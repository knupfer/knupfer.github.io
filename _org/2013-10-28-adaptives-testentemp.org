#+BEGIN_COMMENT
---
layout: post
title: Adaptives Testen
father: Wissenschaft
---
#+END_COMMENT
* Adaptives Testen
Beim adaptiven Testen werden die Möglichkeiten einer computerbasierten Testung in erweitertem Maße ausgenutzt.
Es wird innerhalb der Testung auf Grund der bereits beantworteten Fragen auf den Fähigkeitsgrad des Probanden geschätzt,
um ihm als nächstes eine Frage zu geben, die diesen reflektiert.

#+BEGIN_SRC ditaa :file /images/adaptiveditaa.png :exports code

+---------+   +-----------------+   +---------------+
| Item    |-->| Modellschätzung |-->|   Schätzung   |
| Antwort |   +-----------------+   | nächstes Item |
+---------+                         +---------------+
    ^                                       |
    |                                       |
    +---------------------------------------+

#+END_SRC 

** Kriterien
Wie genau die Frage ausgewählt wird hängt vornehmlich von den Zielen der Testung und den Nebenwirkungen, die man ggf. 
vermeiden möchte, ab. So wäre eine Frage, die der Proband mit einer Chance von 50% lösen kann ideal im Sinne eines 
Informationsgewinnes über den Probanden, da die Entropie maximal ist. 

Entropie stellt nicht nur Chaos, sondern auch Informationsdichte nach Shannon dar 
(vgl. [[http://de.wikipedia.org/wiki/Entropie_%28Informationstheorie%29][Wikipedia]]).
Die folgende Formel ergiebt die Entropie eines Ereignisses. Hierbei ist $n$ die Anzahl der Möglichkeiten und $p_i$ 
die jeweiligen Wahrscheinlichkeiten dieser (sich ausschließender) Möglichkeiten.

$$ H = - \sum_{i=1}^n p_i \cdot \log_2{p_i} $$

Betrachten wir ein binäres System, also nur Fragen die entweder vollständig falsch oder vollständig richtig beantwortet
werden können, so haben wir $n = 2$ und $p_2 = 1 - p_1$.

$$ H_2 = - p \cdot \log_2{p} - (1 - p) \cdot \log_2(1 - p) $$

Hieraus ergiebt sich, dass der Informationsgewinn bei $p = .5$ (im binären) maximal ist, da die Funktion symmetrisch ist und bei
$p = 0$ auf beiden Seiten $0$ ergibt.

$$ H_{max} = - 0.5 \cdot \log_2{0.5} - 0.5 \cdot \log_2{0.5} = 1 \mathrm{bit} $$

Hierbei ist $bit$ die übliche Einheit des Informationsgehaltes, auf Grund des $\log_2$. Es kann also ein Informationsgehalt
von 8 bit mit Hilfe eines bytes dargestellt werden, sprich mit 8 Nullen oder Einsen (z.B. 10101010).

#+BEGIN_SRC R :results output graphics :file /images/entropie.png :exports results
x = (0:100)/100
y = -x*log(x,2)-(1-x)*log(1-x,2)
plot(x,y,type="l",xlab=expression(Lösungswahrscheinlichkeit),ylab=expression("Entropie in bit"),  main="Entropieverteilung")
#+END_SRC

#+RESULTS:
[[file:/images/entropie.png]]

Mit der Formel für tatsächliche und für maximale Entropie kann die Redundanz ausgerechnet werden, welche in einer 
Testkonstruktion als Indikator für das Potential der Verbesserung durch ein adaptives Testverfahren benutzt werden kann.

$$ R = H_{max} - H $$

Somit kann im binären ein Test im idealfall um $R$ Fragen verkleinert werden, ohne an Informationen einzubüßen. 
Befinden sich im Test auch Fragen, die nicht binär sind, so verändert sich die Situation ein wenig.
Die Entropie wird stets maximal bei gleichen Wahrscheinlichkeiten. Gibt es nun bei einer Frage z.B. 0, 1, 2 oder 3 Punkte
gibt es eine maximale Entropie von $H_{max} = - \log_2{0.25} = 2 \mathrm{bit}$. Somit kann man einen Test auch um $R/2$ solcher
Fragen ohne Informationsverlust verkleinern.

*** Informationsgehalt in KoMus
Im August diesen Jahres habe ich mit Teilen des KoMus-Testes für musikalische Kompetenz eine empirische Studie
durchgeführt. Der KoMus-Test liegt in einem nicht adaptiven Format vor.

Interessant ist nun, die Überlegung, wieviel der Test von einer Überführung in einen adaptiven Test profitieren würde.

**** Durchschnittlicher Schüler
Der Simplizität halber können wir annehmen, dass ein Schüler genau die durchschnittlichen Lösungswahrscheinlichkeiten
für ein Item aufweist.

So muss man nur die Entropie mit den klassischen Itemschwierigkeiten der Items berechnen:

$$ H = \sum_{i=1}^n(- P_i \cdot \log_2{P_i} - (1 - P_i) \cdot \log_2(1 - P_i)) $$

Hierbei ist $P_i$ die klassische Itemschwierigkeit des Items $i$ und $n$ die Anzahl der Items. Ferner nimmt diese Formel
nur dichotome Items an.

**** Vierdimensional
Die Entropie ist jedoch eigentlich noch niedriger, wenn man die Schwierigkeiten adaptiv berechnet. Es handelt sich aber
immernoch um einen nicht adaptiven Test mit fester Reihenfolge. Es wird nur eine spezialform der Entropie, die bedingte
Entropie, benutzt (vgl. [[http://de.wikipedia.org/wiki/Bedingte_Entropie][Wikipedia]]).

Um die bedingte Lösungschance und somit auch die bedingte Entropie zu berechnen, werden alle Items der selben Dimension
einer logistisch binären Regression verwendet um die individuell Itemschwierigkeit eines Items der gleichen Dimension zu
berechnen.

$$ H = \sum_{D=1}^4(\sum_{i=1}^{n(D)}(- R \cdot \log_2{R}) - (1 - R) \cdot \log_2(1- R))$$
$$ R = Reg_2(P_{ivD}|\sum_{m=1}^{i(D)-1}P_{vmD}) $$

Hierbei ist $Reg_2(a|b)$ die binärlogistische Regression mit der AV $a$ und den UV $b$.

**** n-Dimensional
Das obige Modell nimmt jedoch an, dass die einzelnen Dimensionen nicht korrelieren und somit Itemantworten einer Dimension 
keine Information (also Entropiesenkung) über andere Dimensionen zulassen.

Dies ist aber eine nicht notwendige Einschränkung, die die Berechnung nicht nur weniger effektiv, sondern auch
komplizierter macht.

Berücksichtigen wir unabhängig von der Dimensionszugehörigkeit einfach alle bereits beantworteten Items, die einen
signifikanten Einfluss auf die Frage haben, haben wir im Endeffekt ein n-dimensionales Modell, wobei $n$ die Anzahl der
Fragen ist.

$$ H = \sum_{i=1}^n(- R \cdot \log_2{R} - (1 - R) \cdot \log_2(1 - R)) $$
$$ R = Reg_2(P_{iv}|\sum_{m=1}^{i-1}P_{vm}) $$

***** Probleme
Mögliche Probleme dieser Methode sind fehlende Datensätze, da die binärlogistische Regression normalerweise alle Fälle
ausschließt, die auch nur bei einem der UV keinen Wert hat. Durch den maßgeschneiderten Testweg ist es bei einem 
Itempool, der nicht komplett erschöpft wird, unmöglich diese Regression so durchzuführen. Dementsprechend müssen
andere Methoden gewählt werden, um mit fehlenden Daten umzugehen.

Eine Möglichkeit wäre, nicht vorhandene Antworten in den Datensätzen zu simulieren. Diese Simulation würde von den Items
die am sichersten geschätzt werden können zu den Items, die schwer geschätzt werden können stattfinden.

Der Grund hierfür liegt daran, dass bei einer sehr sicheren Schätzung der Entropiegehalt sich nur wenig ändert, 
aber es gleich viel mehr Personen gibt, die seriös für schwerere Schätzungen verwendet werden können, was diese
Schätzungen erleichtert.

Die Simulation sollte nach jeder Testung durchgeführt werden, um die Simulation mehr und mehr zu verbessern. Das dieses
Verfahren direkt einen Nutzen erbringt, sollte daran sichtbar sein, dass die Lösungen der alten Datensätze immer besser
retrospektiv vorhergesagt werden können und somit davon außgegangen werden kann, dass auch bei aktuellen Testungen
die Schätzungen besser sind und somit effektiver gemessen werden kann.

* Nicht adaptives Testen
 
* Adaptives Testen

** Umsetzung
   
*** Programmierung
   
**** Initialisierung
#+NAME: statistic
#+BEGIN_SRC R :session stat :exports both :results output :noweb yes
require(MASS)
library(multicore)
library(foreach)
library(doMC)
registerDoMC(8)

calculationtime <- proc.time()
komus = read.table("data/data_komus_bin2.dat",header=TRUE) 
komusmult = data.frame(read.table("data/komus.csv",header=TRUE, sep=','))
multifragen = array(which(sapply(komusmult, max) > 1))
multifragenalt = multifragen
komusmult[multifragen] = lapply(komusmult[multifragen],factor)

FUN.EntropieMC = function(x) {return(rowSums(-x*log(x+0.00000001, 2)))}
FUN.EntropieMC.IND = function(x) {return(sum(-x*log(x+0.00000001, 2)))}
FUN.Entropie = function(x) {return(-x*log(x+0.000001, 2)-(1-x)*log(1-x+0.00001, 2))}
FUN.Chances = function(x) {
    if (length(multifragen) > 0) {
        x[-multifragen] = lapply(x[-multifragen], predict, type="response")
        x[multifragen] = lapply(x[multifragen], predict, type="probs")
    } else {
        x = lapply(x, predict, type="response")
    }
    return(x)
}
FUN.Chances.IND = function(x,y) {
    x[-multifragen] = lapply(x[-multifragen], predict, data = komusmult[y,], type="response")
    x[multifragen] = lapply(x[multifragen], predict, data = komusmult[y,], type="probs")
    return(x)
}
FUN.Entropietemp = function(x) {
    if (length(multifragen) > 0) {
        x[multifragen] = lapply(x[multifragen], FUN.EntropieMC)
        x[-multifragen] =lapply(x[-multifragen], FUN.Entropie)
    } else {
        x =lapply(x, FUN.Entropie)
    }
    x = simplify2array(x)
    return(x)
}
FUN.Entropietemp.IND = function(x) {
    if (length(multifragen) > 0) {
        x[multifragen] = lapply(x[multifragen], FUN.EntropieMC.IND)
        x[-multifragen] =lapply(x[-multifragen], FUN.Entropie)
    } else {
        x =lapply(x, FUN.Entropie)
    }
    x = simplify2array(x)
    return(x)
}

Entropie = NULL
chances = NULL
fitting = NULL
modell = NULL
summe = data.frame()
############
items = length(komusmult)
persons = length(komusmult[,1])
#items = 50
#persons = 2
############

EEE = data.frame(matrix(ncol = 1, nrow = items+1))
SumSD = data.frame(matrix(ncol = 1, nrow = items+1))
RestEntropie = data.frame(matrix(ncol = 1, nrow = items+1))
RestEntropieSD = data.frame(matrix(ncol = 1, nrow = items+1))
names(EEE) = 'kill'
names(SumSD) = 'kill'
names(RestEntropie) = 'kill'
names(RestEntropieSD) = 'kill'
#+END_SRC

#+RESULTS: statistic
#+begin_example
Lade nötiges Paket: MASS
foreach: simple, scalable parallel programming from Revolution Analytics
Use Revolution R for scalability, fault tolerance and more.
http://www.revolutionanalytics.com
Lade nötiges Paket: iterators
Lade nötiges Paket: parallel

Attache Paket: ‘parallel’

The following object(s) are masked from ‘package:multicore’:

    mclapply, mcparallel, pvec
#+end_example

**** Unbedingte und bedingte Entropie in normaler Reihenfolge
#+NAME: statistic1
#+BEGIN_SRC R :session stat :exports both :results output :noweb yes
    modell = NULL
    
    multifragen = multifragen[multifragen <= items]
    if (1 %in% multifragen) {
        modell[[1]] = polr(reformulate('1', names(komusmult[1])), data = komusmult)
    } else {
        modell[[1]] = glm(reformulate('1', names(komusmult[1])), data = komusmult, family = "binomial"(link=logit))
    }
    
    for (i in 2:items) {
        if (i %in% multifragen) {
            modell[[i]] = polr(reformulate(names(komusmult[1:i-1]), names(komusmult[i])), data = komusmult)
        } else {
            modell[[i]] = glm(reformulate(names(komusmult[1:i-1]), names(komusmult[i])), data = komusmult, family = "binomial"(link=logit))
        }
    }
    
    fitting = modell
    <<fitting>>
    chances = FUN.Chances(fitting)
    
    Entropietemp = FUN.Entropietemp(chances)
    
    ### Without relations ###
    fitting = lapply(fitting, update, ~ 1)
    chances2 = FUN.Chances(fitting)
    
    Entropietemp2 = FUN.Entropietemp(chances2)
    
    multifragen = multifragenalt
    
    SumSDtemp = sd(Entropietemp[,1])
    for (i in 2:length(Entropietemp[1,])) {
        SumSDtemp[i] = sd(rowSums(Entropietemp[,1:i]))
    }
    
    SumSD$bedunsort = c(0,SumSDtemp)
    
    EEE$bedunsort = c(0,colMeans(Entropietemp))
    EEE$unbedunsort = c(0,colMeans(Entropietemp2))
    EEE$unbedsort = c(0,sort(colMeans(Entropietemp2), decreasing =TRUE))
    Entropietemp2 = data.frame(Entropietemp2)
    names(Entropietemp2) = names(komusmult[1:length(Entropietemp2)])    
#+END_SRC

#+RESULTS: statistic1
#+begin_example
 Warnmeldung:
glm.fit: Angepasste Wahrscheinlichkeiten mit numerischem Wert 0 oder 1 aufgetreten
  X.D1124   D110a15   D110a25   D110a35   D113a16   D113a26   D113a56     D114a 
0.8125020 0.8861997 0.9456444 0.9575376 0.9962310 0.9855816 0.9974236 0.9983886 
    D114c     D114d   D115a23   D115c12    D11613  D118eMCe     D119a   D119b13 
0.9799795 0.9931612 0.9698238 0.6840226 0.9987858 0.8935552 0.8625120 0.9991262 
   D12012    D12022       D17     D1916     D1926    D21c12    D21c22      D21d 
0.8746628 0.8768192 0.9698238 0.9140434 0.8222512 0.9404598 0.9902579 2.0683589 
     D23b      D24a      D24b      D24e      D24h      D25a    D26a55     D26b1 
1.7420188 0.8075145 0.9716635 0.8899108 0.5084451 0.9955492 0.9350282 0.5446476 
    D26b2  D110b12b      D31a      D31b       D32      D34a      D36a      D36b 
0.7231644 0.9968558 0.8971335 0.8125020 2.3292270 2.7217770 0.9799795 0.9172315 
     D37b      D37c      D41d     D41f1     D41f2     D41f3     D4215     D4235 
0.8583232 0.9639492 2.4235068 0.9979345 0.9481447 0.9264135 0.9074743 0.9998069 
   D43a23    D43a33    D44a44    D45a14    D45a24    D45b26 
0.7704334 0.9172315 0.8540645 0.8785761 0.7591200 0.7293722
#+end_example

**** Bedingte, sortierte Entropie
#+NAME: statistic2
#+BEGIN_SRC R :session stat :exports both :results output :noweb yes
    modell = NULL
    chances = NULL
    fitting = NULL
    
    ############## sortierte Reihenfolge
    for (i in 1:items) {
        if (i %in% multifragen) {
            modell[[i]] = polr(reformulate('1', names(komusmult[i])), data = komusmult)
        } else {
            modell[[i]] = glm(reformulate('1', names(komusmult[i])), data = komusmult, family = "binomial"(link=logit))
        }
    }
    
    chances = FUN.Chances(modell)
    Entropietemp = FUN.Entropietemp(chances)
    Entropietemp = data.frame(Entropietemp)
    names(Entropietemp) = names(komusmult[1:length(Entropietemp)])
    komus2 = komusmult[c(names(sort(colMeans(Entropietemp), decreasing=TRUE)))]
    #########
    
    names(sort(colMeans(Entropietemp), decreasing=TRUE))
    multifragen.alt = multifragen
    multifragen.alt
    multifragen = which(names(komus2) %in% names(komusmult[multifragen.alt]))
    modell = NULL
    fitting = NULL
    chances = NULL
    
    if (1 %in% multifragen) {
        modell[[1]] = polr(reformulate('1', names(komus2[1])), data = komus2)
    } else {
        modell[[1]] = glm(reformulate('1', names(komus2[1])), data = komus2, family = "binomial"(link=logit))
    }
    
    for (i in 2:items) {
        if (i %in% multifragen) {
            modell[[i]] = polr(reformulate(names(komus2[1:i-1]), names(komus2[i])), data = komus2)
        } else {
            modell[[i]] = glm(reformulate(names(komus2[1:i-1]), names(komus2[i])), data = komus2, family = "binomial"(link=logit))
        }
    }
    
    fitting = modell
    <<fitting>>
    chances = FUN.Chances(fitting)
    #chances[-multifragen] = mclapply(fitting[-multifragen], predict, type="response")
    #chances[multifragen] = mclapply(fitting[multifragen], predict, type="probs")
    
    #Entropietemp = fitting
    Entropietemp = FUN.Entropietemp(chances)
    #Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC)
    #Entropietemp[-multifragen] =lapply(chances[-multifragen], FUN.Entropie)
    #Entropietemp = simplify2array(Entropietemp)
    
    SumSDtemp = sd(Entropietemp[,1])
    for (i in 2:length(Entropietemp[1,])) {
        SumSDtemp[i] = sd(rowSums(Entropietemp[,1:i]))
    }
    
    SumSD$sortbed = c(0,SumSDtemp)
    
    EEE$sortbed = c(0,colMeans(Entropietemp))
    
    multifragen = multifragen.alt
#+END_SRC

#+RESULTS: statistic2
#+begin_example
 [1] "D34a"     "D41d"     "D32"      "D21d"     "D23b"     "D4235"   
 [7] "D119b13"  "D11613"   "D114a"    "D41f1"    "D113a56"  "D110b12b"
[13] "D113a16"  "D25a"     "D114d"    "D21c22"   "D113a26"  "D114c"   
[19] "D36a"     "D24b"     "D115a23"  "D17"      "D37c"     "D110a35" 
[25] "D41f2"    "D110a25"  "D21c12"   "D26a55"   "D41f3"    "D43a33"  
[31] "D36b"     "D1916"    "D4215"    "D31a"     "D118eMCe" "D24e"    
[37] "D110a15"  "D45a14"   "D12022"   "D12012"   "D119a"    "D37b"    
[43] "D44a44"   "D1926"    "X.D1124"  "D31b"     "D24a"     "D43a23"  
[49] "D45a24"   "D45b26"   "D26b2"    "D115c12"  "D26b1"    "D24h"
[1] 18 24 25 37 38 43
 Warnmeldungen:
1: glm.fit: fitted probabilities numerically 0 or 1 occurred 
2: glm.fit: fitted probabilities numerically 0 or 1 occurred 
3: glm.fit: Angepasste Wahrscheinlichkeiten mit numerischem Wert 0 oder 1 aufgetreten 
4: glm.fit: Angepasste Wahrscheinlichkeiten mit numerischem Wert 0 oder 1 aufgetreten 
5: glm.fit: Algorithmus konvergierte nicht 
6: glm.fit: Angepasste Wahrscheinlichkeiten mit numerischem Wert 0 oder 1 aufgetreten 
7: glm.fit: Angepasste Wahrscheinlichkeiten mit numerischem Wert 0 oder 1 aufgetreten
#+end_example

**** Durchschnittlich bedingtsortierte Entropie
#+NAME: statistic3
#+BEGIN_SRC R :session stat :exports both :results output :noweb yes
    fragen = NULL
    modell = NULL
    Restentropietemp = NULL
    multifragenalt = multifragen
    ############## sortierte Reihenfolge
    for (i in 1:length(komusmult)) {
        if (i %in% multifragen) {
            fitting[[i]] = polr(reformulate('1', names(komusmult[i])), data = komusmult)
        } else {
            fitting[[i]] = glm(reformulate('1', names(komusmult[i])), data = komusmult, family = "binomial"(link=logit))
        }
    }
    #modell
    chances = FUN.Chances(fitting)
    
    Entropietemp = FUN.Entropietemp(chances)
    
    fragen = which(names(komusmult[which(colMeans(Entropietemp) == max(colMeans(Entropietemp)))]) == names(komusmult))
    fragen
    #########
    modell[[1]] = fitting[[fragen]]
    
    for (i in 2:items) {
        Entropietemp = NULL
        fitting = NULL
    
        multifragen = which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt]))
    
        for (j in 1:length(komusmult[-fragen])) {
            if (j %in% multifragen) {
                fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
            } else {
                fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
            }
        }
        <<fitting>>
        chances = FUN.Chances(fitting)
    
        Entropietemp = FUN.Entropietemp(chances)
        Restentropietemp[[i-1]] = rowSums(Entropietemp)
    
        fragen = c(fragen, which(names(komusmult[-fragen][which(colMeans(Entropietemp) == max(colMeans(Entropietemp)))]) == names(komusmult)))
        modell[[i]] = fitting[[which(colMeans(Entropietemp) == max(colMeans(Entropietemp)))]]
    }
    
    if (length(komusmult) == items) {
        Restentropietemp[[items]] = Restentropietemp[[1]]*0
    } else {
        fitting = NULL
    
        multifragen = which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt]))
    
        for (j in 1:length(komusmult[-fragen])) {
            if (j %in% multifragen) {
                fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
            } else {
                fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
            }
        }
        <<fitting>>
        chances = FUN.Chances(fitting)
        Entropietemp = FUN.Entropietemp(chances)
        Restentropietemp[[items]] = rowSums(Entropietemp)
    }
    multifragen = which(fragen %in% multifragenalt)
    
    Restentropietemp = simplify2array(Restentropietemp)
    
    chances = FUN.Chances(modell)
    Entropietemp = FUN.Entropietemp(chances)
    
    SumSDtemp = sd(Entropietemp[,1])
    for (i in 2:length(Entropietemp[1,])) {
    SumSDtemp[i] = sd(rowSums(Entropietemp[,1:i]))
    }
    
    SumSD$durchschbedsort = c(0,SumSDtemp)
    EEE$durchschbedsort = c(0,colMeans(Entropietemp))
    RestEntropie$durchschbedsort = c(0,colMeans(Restentropietemp))
    RestEntropieSD$durchschbedsort = c(0,apply(Restentropietemp, 2, sd))
#+END_SRC

#+RESULTS: statistic3
: [1] 38
:  Es gab 50 oder mehr Warnungen (Anzeige der ersten 50 mit warnings())

**** Individuellbedingtsortierte Entropie
#+NAME: statistic4
#+BEGIN_SRC R :session stat :exports both :results output :noweb yes
    ## initializing
    Entropieall = NULL
    chances = NULL
    Restentropietemp = NULL
    fragen = NULL
    modell = NULL
    Restentropietemp = NULL
    multifragen = multifragenalt
    fitting = NULL
    
    ## first item
    for (i in 1:length(komusmult)) {
        if (i %in% multifragen) {
            fitting[[i]] = polr(reformulate('1', names(komusmult[i])), data = komusmult)
        } else {
            fitting[[i]] = glm(reformulate('1', names(komusmult[i])), data = komusmult, family = "binomial"(link=logit))
        }
    }
    
    chances = fitting
    chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[1,], type="response")
    chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[1,], type="probs")
    Entropietemp = FUN.Entropietemp.IND(chances)
    fragen = which(names(komusmult[which(Entropietemp == max(Entropietemp))]) == names(komusmult))
    
    modell[[1]] = fitting[[fragen]]
    frageninit = fragen
    fitting = NULL
    
    ## multicorecalculation for every person
    Entropieall = simplify2array(foreach(k=1:persons) %dopar% {
        fragen = frageninit
        Restentropie = NULL
        for (i in 2:items) {
            chances = NULL
            Entropietemp = NULL
            fitting = NULL
            multifragen = 0
            multifragen = c(multifragen,which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt])))
            for (j in 1:length(komusmult[-fragen])) {
                if (j %in% multifragen) {
                    fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
                } else {
                    fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
                }
            }
            <<fitting>>
            chances = fitting
            
            ## chosing next item with highest entropie
            if (length(multifragen) == 1) {
                chances = lapply(fitting, predict, komusmult[k,], type="response")
                Entropietemp = chances
                Entropietemp = lapply(chances, FUN.Entropie)
                Entropietemp = simplify2array(Entropietemp)
            } else {
                multifragen = multifragen[2:length(multifragen)]
                chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[k,], type="response")
                chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[k,], type="probs")
                Entropietemp = chances
                
                ## TODO perhaps, functions don't work 
                Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC.IND)
                Entropietemp[-multifragen] = lapply(chances[-multifragen], FUN.Entropie)
                Entropietemp = simplify2array(Entropietemp)
            }
            
            Restentropietemp[i-1] = sum(Entropietemp) #rest of entropie before this item
            fragen = c(fragen, which(names(komusmult[-fragen][which(Entropietemp == max(Entropietemp))]) == names(komusmult)))
            modell[[i]] = fitting[[which(Entropietemp == max(Entropietemp))]]
        }
        
        ## calculation of last rest entropie
        if (length(komusmult) == items) {
            Restentropietemp[items] = 0
        } else {
            fitting = NULL
            multifragen = 0
            multifragen = c(0,which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt])))
            for (j in 1:length(komusmult[-fragen])) {
                if (j %in% multifragen) {
                    fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
                } else {
                    fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
                }
            }
            <<fitting>>
                
            if (length(multifragen) == 1) {
                chances = lapply(fitting, predict, komusmult[k,], type="response")
                Entropietemp = chances
                Entropietemp = lapply(chances, FUN.Entropie)
                Entropietemp = simplify2array(Entropietemp)
            } else {
                multifragen = multifragen[2:length(multifragen)]
                chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[k,], type="response")
                chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[k,], type="probs")
                Entropietemp = chances
                
                Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC.IND)
                Entropietemp[-multifragen] = lapply(chances[-multifragen], FUN.Entropie)
                Entropietemp = simplify2array(Entropietemp)
            }
            
            Restentropietemp[items] = sum(Entropietemp)
        }
        
        ## calculation of the choosen modell
        multifragen = 0
        multifragen = c(multifragen,which(fragen %in% multifragenalt))
        if (length(multifragen) == 1) {
            chances = modell
            chances = lapply(modell, predict, komusmult[k,], type="response")
            Entropietemp = chances
            Entropietemp = lapply(chances, FUN.Entropie)
            Entropietemp = simplify2array(Entropietemp)
        } else {
            multifragen = multifragen[2:length(multifragen)]
            chances = modell
            chances[-multifragen] = lapply(modell[-multifragen], predict, komusmult[k,], type="response")
            chances[multifragen] = lapply(modell[multifragen], predict, komusmult[k,], type="probs")
            Entropietemp = chances
            
            Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC.IND)
            Entropietemp[-multifragen] = lapply(chances[-multifragen], FUN.Entropie)
            Entropietemp = simplify2array(Entropietemp)
        }
        
        return(c(Entropietemp, Restentropietemp))    
    })
    
    Restentropietemp = (Entropieall[(items+1):(items*2),])
    Entropieall = Entropieall[1:items,]
     
    SumSDtemp = sd(Entropieall[1,])
    for (i in 2:length(Entropieall[,1])) {
        SumSDtemp[i] = sd(colSums(Entropieall[1:i,]))
    }
     
    SumSD$indivbedsort = c(0,SumSDtemp)
    EEE$indivbedsort = c(0,rowMeans(Entropieall))
    RestEntropie$indivbedsort = c(0,rowMeans(Restentropietemp))
    RestEntropieSD$indivbedsort = c(0,apply(Restentropietemp, 1, sd))
    
    multifragen = multifragenalt
#+END_SRC

#+RESULTS: statistic4
#+begin_example
   kill  indivbedsort
1    NA  0.000000e+00
2    NA  2.721777e+00
3    NA  2.432670e+00
4    NA  2.154384e+00
5    NA  1.975223e+00
6    NA  1.645492e+00
7    NA  9.998728e-01
8    NA  1.002401e+00
9    NA  9.992680e-01
10   NA  9.992376e-01
11   NA  9.996730e-01
12   NA  9.999130e-01
13   NA  9.981415e-01
14   NA  9.989579e-01
15   NA  9.971855e-01
16   NA  9.948196e-01
17   NA  9.901890e-01
18   NA  9.884324e-01
19   NA  9.968586e-01
20   NA  9.905953e-01
21   NA  9.822517e-01
22   NA  9.740095e-01
23   NA  9.781170e-01
24   NA  9.703556e-01
25   NA  9.709585e-01
26   NA  9.744011e-01
27   NA  9.852493e-01
28   NA  9.480422e-01
29   NA  9.207892e-01
30   NA  9.091900e-01
31   NA  9.027296e-01
32   NA  8.991390e-01
33   NA  8.393290e-01
34   NA  8.459918e-01
35   NA  8.447474e-01
36   NA  7.623495e-01
37   NA  7.030355e-01
38   NA  6.906098e-01
39   NA  6.707320e-01
40   NA  6.275486e-01
41   NA  5.542715e-01
42   NA  5.458267e-01
43   NA  4.408620e-01
44   NA  4.240422e-01
45   NA  3.365356e-01
46   NA  3.718148e-01
47   NA  2.759980e-01
48   NA  2.811121e-01
49   NA  1.985363e-01
50   NA  1.345265e-01
51   NA  1.214295e-01
52   NA  5.141231e-02
53   NA  1.179508e-02
54   NA  3.029522e-03
55   NA -5.770756e-06
   kill indivbedsort
1    NA  0.000000000
2    NA  0.000000000
3    NA  0.009027186
4    NA  0.058175471
5    NA  0.036887934
6    NA  0.249079208
7    NA  0.248986880
8    NA  0.251734351
9    NA  0.251355632
10   NA  0.251850701
11   NA  0.252317169
12   NA  0.252293466
13   NA  0.251128547
14   NA  0.250552701
15   NA  0.248486026
16   NA  0.245221906
17   NA  0.237280890
18   NA  0.224736273
19   NA  0.222729805
20   NA  0.213474477
21   NA  0.202864938
22   NA  0.181967838
23   NA  0.162761475
24   NA  0.137173282
25   NA  0.116580339
26   NA  0.096995491
27   NA  0.099342419
28   NA  0.084862541
29   NA  0.126204239
30   NA  0.243648348
31   NA  0.385627284
32   NA  0.530251300
33   NA  0.650850438
34   NA  0.769100466
35   NA  0.916306970
36   NA  1.021972354
37   NA  1.116760468
38   NA  1.250866440
39   NA  1.289650757
40   NA  1.329302019
41   NA  1.434448147
42   NA  1.559052828
43   NA  1.619351077
44   NA  1.683992073
45   NA  1.713294697
46   NA  1.833789948
47   NA  1.922849626
48   NA  2.040543021
49   NA  2.133639668
50   NA  2.202070286
51   NA  2.300427561
52   NA  2.315507271
53   NA  2.313326081
54   NA  2.317056723
55   NA  2.317055596
   kill  indivbedsort
1    NA  0.000000e+00
2    NA  5.135908e+01
3    NA  4.881582e+01
4    NA  4.562663e+01
5    NA  4.325132e+01
6    NA  4.112426e+01
7    NA  4.042258e+01
8    NA  3.854947e+01
9    NA  3.716378e+01
10   NA  3.618153e+01
11   NA  3.519636e+01
12   NA  3.388109e+01
13   NA  3.279737e+01
14   NA  3.180080e+01
15   NA  3.026254e+01
16   NA  2.864349e+01
17   NA  2.724371e+01
18   NA  2.623535e+01
19   NA  2.508785e+01
20   NA  2.405066e+01
21   NA  2.277454e+01
22   NA  2.177713e+01
23   NA  2.034057e+01
24   NA  1.946257e+01
25   NA  1.803385e+01
26   NA  1.721388e+01
27   NA  1.597181e+01
28   NA  1.498193e+01
29   NA  1.396405e+01
30   NA  1.307385e+01
31   NA  1.191703e+01
32   NA  1.097635e+01
33   NA  1.016586e+01
34   NA  9.202684e+00
35   NA  7.899795e+00
36   NA  7.097354e+00
37   NA  6.081928e+00
38   NA  5.460851e+00
39   NA  4.772650e+00
40   NA  4.067948e+00
41   NA  3.413253e+00
42   NA  2.846556e+00
43   NA  2.350530e+00
44   NA  1.769718e+00
45   NA  1.480445e+00
46   NA  1.097974e+00
47   NA  7.927647e-01
48   NA  5.259278e-01
49   NA  3.187139e-01
50   NA  1.914815e-01
51   NA  6.822902e-02
52   NA  1.518414e-02
53   NA  3.023751e-03
54   NA -5.770756e-06
55   NA  0.000000e+00
   kill indivbedsort
1    NA 0.000000e+00
2    NA 7.362653e-01
3    NA 3.176987e-01
4    NA 4.793886e-01
5    NA 5.785675e-01
6    NA 6.393388e-01
7    NA 9.577214e-01
8    NA 1.274269e+00
9    NA 2.027016e+00
10   NA 1.909940e+00
11   NA 1.643141e+00
12   NA 1.960404e+00
13   NA 1.964451e+00
14   NA 1.529076e+00
15   NA 1.878734e+00
16   NA 2.053826e+00
17   NA 2.220281e+00
18   NA 2.052133e+00
19   NA 1.876594e+00
20   NA 2.009701e+00
21   NA 1.974349e+00
22   NA 1.933595e+00
23   NA 2.002850e+00
24   NA 1.692322e+00
25   NA 1.799258e+00
26   NA 1.725785e+00
27   NA 1.812078e+00
28   NA 1.929145e+00
29   NA 1.743920e+00
30   NA 1.755639e+00
31   NA 1.502964e+00
32   NA 1.570259e+00
33   NA 1.452640e+00
34   NA 1.378060e+00
35   NA 1.133211e+00
36   NA 1.130159e+00
37   NA 9.339317e-01
38   NA 7.751506e-01
39   NA 9.749697e-01
40   NA 8.970542e-01
41   NA 8.093955e-01
42   NA 6.485482e-01
43   NA 6.307331e-01
44   NA 5.379630e-01
45   NA 6.920624e-01
46   NA 5.264797e-01
47   NA 3.919423e-01
48   NA 2.473037e-01
49   NA 2.055540e-01
50   NA 1.517166e-01
51   NA 3.453077e-02
52   NA 7.483717e-03
53   NA 4.935855e-03
54   NA 7.496422e-06
55   NA 0.000000e+00
#+end_example

**** Individuellbedingtsortierte Entropie mit Trennschärfe
#+NAME: statistic5
#+BEGIN_SRC R :session stat :exports both :results output :noweb yes
    Entropieall = NULL
    chances = NULL
    beta = NULL
    Restentropietemp = NULL
    Entropietemp = NULL
    fitting = NULL
    
    if (!exists("information")) {
        information = simplify2array(foreach(m=1:length(komus)) %dopar% {
            for (n in 1:(length(komus)-1)) {
                beta[[n]] = glm(reformulate(names(komus[m]), names(komus[-m][n])), data = komus, family = "binomial"(link=logit))
            }
            chances = simplify2array(lapply(beta, predict, type="response"))
            chancetemp = unlist(lapply(komus[m],mean))
            Entropietemp = (-chances*log(chances,2)-(1-chances)*log(1-chances,2))
            information = sum(colMeans(Entropietemp)) + (-chancetemp*log(chancetemp,2)-(1-chancetemp)*log(1-chancetemp,2))
            return(information)
        })
        information = -(information - sum(-colMeans(komus)*log(colMeans(komus),2)-(1-colMeans(komus))*log(1-colMeans(komus),2)))
    }
    
    
    
    
    
    for (j in 1:length(komus)) {
        fitting[[j]] = glm(reformulate('1', names(komus[j])), data = komus, family = "binomial"(link=logit))
    }
    <<fitting>>
    chances = simplify2array(lapply(fitting, predict, komus[1,], type="response"))
    Entropietemp = (-chances*log(chances,2)-(1-chances)*log(1-chances,2)) + (information)
    frageninit = which(names(komus[which((Entropietemp) == max((Entropietemp)))]) == names(komus))
    
     
    
    modell[[1]] = fitting[[which((Entropietemp) == max((Entropietemp)))]]
    
    Entropieall = simplify2array(foreach(k=1:persons) %dopar% {
        fragen = frageninit
        for (i in 2:items) {
            Entropietemp = NULL
            fitting = NULL
            for (j in 1:length(komus[-fragen])) {
                fitting[[j]] = glm(reformulate(names(komus[fragen]), names(komus[-fragen][j])), data = komus, family = "binomial"(link=logit))
            }
    
            <<fitting>>
            ## TODO stimmt das so?
            chances = simplify2array(lapply(fitting, predict, komus[k,], type="response"))
            Restentropietemp[i-1] = sum(-chances*log(chances,2)-(1-chances)*log(1-chances,2)) 
            Entropietemp = (-chances*log(chances,2)-(1-chances)*log(1-chances,2)) + (information[-fragen]*(1 - (length(fragen)+1)/items))
            fragen = c(fragen, which(names(komus[-fragen][which((Entropietemp) == max((Entropietemp)))]) == names(komus)))
            modell[[i]] = fitting[[which((Entropietemp) == max((Entropietemp)))]]
        }
    
        if (length(komus) == items) {
            Restentropietemp[items] = 0
        } else {
            fitting = NULL
            for (j in 1:length(komus[-fragen])) {
                fitting[[j]] = glm(reformulate(names(komus[fragen]), names(komus[-fragen][j])), data = komus, family = "binomial"(link=logit))
            }
            <<fitting>>
            chances = simplify2array(lapply(fitting, predict, komus[k,], type="response"))
            Restentropietemp[length(fragen)] = sum(-chances*log(chances,2)-(1-chances)*log(1-chances,2))
        }
    
        chances = simplify2array(lapply(modell, predict, komus[k,], type="response"))
        Entropietemp = (-chances*log(chances,2)-(1-chances)*log(1-chances,2))
        
        return(c(Entropietemp, Restentropietemp))
    })
    
    Restentropietemp = (Entropieall[(items+1):(items*2),])
    Entropieall = Entropieall[1:items,]
    SumSDtemp = sd(Entropieall[1,])
    for (i in 2:length(Entropieall[,1])) {
    SumSDtemp[i] = sd(colSums(Entropieall[1:i,]))
    }
    
    SumSD$indivbedsorttrenn = c(0,SumSDtemp )
    EEE$indivbedsorttrenn = c(0,rowMeans(Entropieall))
    RestEntropie$indivbedsorttrenn = c(0,rowMeans(Restentropietemp))
    RestEntropieSD$indivbedsorttrenn = c(0,apply(Restentropietemp,1 ,sd))
#+END_SRC

#+RESULTS: statistic5

**** Individuellbedingtsortierte Entropie mit Prädiktion
#+NAME: statistic6
#+BEGIN_SRC R :session stat :exports code :results output :noweb yes
    ## initializing
    fitting = NULL
    Entropieall = NULL
    chances = NULL
    Restentropietemp = NULL
    fragen = NULL
    modell = NULL
    Restentropietemp = NULL
    multifragen = multifragenalt
    
    ## first item
    for (i in 1:length(komusmult)) {
        if (i %in% multifragen) {
            fitting[[i]] = polr(reformulate('1', names(komusmult[i])), data = komusmult)
        } else {
            fitting[[i]] = glm(reformulate('1', names(komusmult[i])), data = komusmult, family = "binomial"(link=logit))
        }
    }
    
    chances = fitting
    chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[1,], type="response")
    chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[1,], type="probs")
    Entropietemp = FUN.Entropietemp.IND(chances)
    fragen = which(names(komusmult[which(Entropietemp == max(Entropietemp))]) == names(komusmult))
    
    modell[[1]] = fitting[[fragen]]
    frageninit = fragen
    fitting = NULL
    Restentropie2 = NULL
    
    ## multicore calculation
    Entropieall = simplify2array(foreach(k=1:persons) %dopar% {
        fragen = frageninit
        Restentropie = NULL
        Restentropietemp2 = NULL
        Restentropietemp = NULL
        for (i in 2:items) {
            chances = NULL
            Entropietemp = NULL
            fitting = NULL
            fitting2 = NULL
            fittingplus = NULL
            fittingminus = NULL
            Entropietemp2 = NULL
            multifragen = 0
            multifragen = c(multifragen,which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt])))
            
            ## prediction for all not-answerd questions
            for (j in 1:length(komusmult[-fragen])) {
                if (j %in% multifragen) {
                    fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
                } else {
                    fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
                }
                
                ## prediction for all not-answered questions after prediction
                if (length(komusmult[-fragen]) > 1) {
                    multifragen2 = c(0,which(names(komusmult[-fragen][-j]) %in% names(komusmult[multifragenalt])))
                    for (n in 1:length(komusmult[-fragen][-j])) {
                        if (n %in% multifragen2) {
                            fitting2[[n]] = polr(reformulate(names(c(komusmult[fragen], komusmult[-fragen][j])), names(komusmult[-fragen][-j][n])), data = komusmult)
                        } else {
                            fitting2[[n]] = glm(reformulate(names(c(komusmult[fragen], komusmult[-fragen][j])), names(komusmult[-fragen][-j][n])), data = komusmult, family = "binomial"(link=logit))
                        }
                    }
                    
                    ## calculation of rest entropie for each possibility
                    tempdata = komusmult[k,]
                    ##tempdata[-fragen][j] = 0 #dies muss noch bearbeitet werden (chancen...)
                    <<fitting>>
                        chances = fitting2
                    if (length(multifragen2) == 1) {
                        chances = lapply(fitting2, predict, tempdata, type="response")
                        Entropietemp = chances
                        Entropietemp = lapply(chances, FUN.Entropie)
                        Entropietemp = simplify2array(Entropietemp)
                    } else {
                        multifragen2 = multifragen2[2:length(multifragen2)]
                        chances[-multifragen2] = lapply(fitting2[-multifragen2], predict, tempdata, type="response")
                        chances[multifragen2] = lapply(fitting2[multifragen2], predict, tempdata, type="probs")
                        Entropietemp = chances
                        
                        ## Funktion kann nicht benutzt werden, da sie auf nicht manipulierte multifragen zugreift
                        Entropietemp[multifragen2] = lapply(chances[multifragen2], FUN.EntropieMC.IND)
                        Entropietemp[-multifragen2] = lapply(chances[-multifragen2], FUN.Entropie)
                        Entropietemp = simplify2array(Entropietemp)
                    }
                    
                    Restentropietemp2[j] = sum(Entropietemp)
                } else {
                    Restentropietemp2[j] = 0 
                }
            }
            
            <<fitting>>
                chances = fitting
            
            ## calculation of current rest entropie
            if (length(multifragen) == 1) {
                chances = lapply(fitting, predict, komusmult[k,], type="response")
                Entropietemp = chances
                Entropietemp = lapply(chances, FUN.Entropie)
                Entropietemp = simplify2array(Entropietemp)
            } else {
                multifragen = multifragen[2:length(multifragen)]
                chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[k,], type="response")
                chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[k,], type="probs")
                Entropietemp = chances
                
                ## Funktion kann nicht benutzt werden, da sie auf nicht manipulierte multifragen zugreift
                Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC.IND)
                Entropietemp[-multifragen] = lapply(chances[-multifragen], FUN.Entropie)
                Entropietemp = simplify2array(Entropietemp)
            }
            
            Restentropietemp[i-1] = sum(Entropietemp)
            fragen = c(fragen, which(names(komusmult[-fragen][which(Restentropietemp2 == min(Restentropietemp2))]) == names(komusmult)))
            ## stimmt das? sollte das nicht mit Restentropietemp2 arbeiten?
            ##        modell[[i]] = fitting[[which(Entropietemp == max(Entropietemp))]]
            modell[[i]] = fitting[[which(Restentropietemp2 == min(Restentropietemp2))]]
        }
        
        ## calculation of last rest entropie
        if (length(komusmult) == items) {
            Restentropietemp[items] = 0
        } else {
            fitting = NULL
            multifragen = 0
            multifragen = c(0,which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt])))
            for (j in 1:length(komusmult[-fragen])) {
                if (j %in% multifragen) {
                    fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
                } else {
                    fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
                }
            }
            
            <<fitting>>
                if (length(multifragen) == 1) {
                    chances = lapply(fitting, predict, komusmult[k,], type="response")
                    Entropietemp = chances
                    Entropietemp = lapply(chances, FUN.Entropie)
                    Entropietemp = simplify2array(Entropietemp) 
                } else {
                    multifragen = multifragen[2:length(multifragen)]
                    chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[k,], type="response")
                    chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[k,], type="probs")
                    Entropietemp = chances
                    
                    ## Funktion kann nicht benutzt werden, da sie auf nicht manipulierte multifragen zugreift
                    Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC.IND)
                    Entropietemp[-multifragen] = lapply(chances[-multifragen], FUN.Entropie)
                    Entropietemp = simplify2array(Entropietemp)
                }
            
        Restentropietemp[items] = sum(Entropietemp)
        }
        
        ## calculation of choosen modell
        multifragen = 0
        multifragen = c(multifragen,which(fragen %in% multifragenalt))
        if (length(multifragen) == 1) {
            chances = modell
            chances = lapply(modell, predict, komusmult[k,], type="response")
            Entropietemp = chances
            Entropietemp = lapply(chances, FUN.Entropie)
            Entropietemp = simplify2array(Entropietemp)
        } else {
            multifragen = multifragen[2:length(multifragen)]
            chances = modell
            chances[-multifragen] = lapply(modell[-multifragen], predict, komusmult[k,], type="response")
            chances[multifragen] = lapply(modell[multifragen], predict, komusmult[k,], type="probs")
            Entropietemp = chances
            
            ## Funktion kann nicht benutzt werden, da sie auf nicht manipulierte multifragen zugreift
            Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC.IND)
            Entropietemp[-multifragen] = lapply(chances[-multifragen], FUN.Entropie)
            Entropietemp = simplify2array(Entropietemp)
        }
        
        return(c(Entropietemp, Restentropietemp))    
    })
    
    Restentropietemp = (Entropieall[(items+1):(items*2),])
    Entropieall = Entropieall[1:items,]
    
    SumSDtemp = sd(Entropieall[1,])
    for (i in 2:length(Entropieall[,1])) {
        SumSDtemp[i] = sd(colSums(Entropieall[1:i,]))
    }
    
    SumSD$indivbedsortpred = c(0,SumSDtemp)
    EEE$indivbedsortpred = c(0,rowMeans(Entropieall))
    RestEntropie$indivbedsortpred = c(0,rowMeans(Restentropietemp))
    RestEntropieSD$indivbedsortpred = c(0,apply(Restentropietemp, 1, sd))
    
    multifragen = multifragenalt
    EEE
    SumSD
    RestEntropie
    RestEntropieSD
#+END_SRC

**** Experimenteller Code
#+BEGIN_SRC R :session stat :exports code :results output :noweb yes
calculationtime <- proc.time()



Entropieall = NULL
chances = NULL
Restentropietemp = NULL

fragen = NULL
modell = NULL
Restentropietemp = NULL
multifragen = multifragenalt
############## sortierte Reihenfolge
for (i in 1:length(komusmult)) {
    if (i %in% multifragen) {
        fitting[[i]] = polr(reformulate('1', names(komusmult[i])), data = komusmult)
    } else {
        fitting[[i]] = glm(reformulate('1', names(komusmult[i])), data = komusmult, family = "binomial"(link=logit))
   }
}
#modell
chances = fitting
chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[1,], type="response")
chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[1,], type="probs")
#chances = FUN.Chances.IND(fitting, 1)

Entropietemp = FUN.Entropietemp.IND(chances)

#Entropietemp

fragen = which(names(komusmult[which(Entropietemp == max(Entropietemp))]) == names(komusmult))
#fragen

######## bisher alles korrekt.
#########
modell[[1]] = fitting[[fragen]]

frageninit = fragen
fitting = NULL


Entropieall = simplify2array(foreach(k=1:persons) %dopar% {
#foreach(k=1:persons) %dopar% {
#k = 3

    fragen = frageninit
    Restentropie = NULL
    for (i in 2:items) {
        chances = NULL
        Entropietemp = NULL
        fitting = NULL
        multifragen = 0
        multifragen = c(multifragen,which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt])))

        for (j in 1:length(komusmult[-fragen])) {
            if (j %in% multifragen) {
                fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
            } else {
                fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
            }
        }
 #       <<fitting>>
#        chances = lapply(fitting, step)
#print(komusmult[k,])
chances = fitting
        if (length(multifragen) == 1) {
        chances = lapply(fitting, predict, komusmult[k,], type="response")
        Entropietemp = chances
        Entropietemp = lapply(chances, FUN.Entropie)
        Entropietemp = simplify2array(Entropietemp)

} else {
        multifragen = multifragen[2:length(multifragen)]
        chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[k,], type="response")
        chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[k,], type="probs")
        Entropietemp = chances
#print(chances)
### Funktion kann nicht benutzt werden, da sie auf nicht manipulierte multifragen zugreift
        Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC.IND)
        Entropietemp[-multifragen] = lapply(chances[-multifragen], FUN.Entropie)
        Entropietemp = simplify2array(Entropietemp)}
#print(Entropietemp)
        Restentropietemp[i-1] = sum(Entropietemp)
#print(Restentropietemp)
        fragen = c(fragen, which(names(komusmult[-fragen][which(Entropietemp == max(Entropietemp))]) == names(komusmult)))
        modell[[i]] = fitting[[which(Entropietemp == max(Entropietemp))]]
    }
#return(Restentropietemp)
#}
#5555555555555555555555555
 
    if (length(komusmult) == items) {
        Restentropietemp[items] = 0
    } else {
        fitting = NULL
        multifragen = 0
        multifragen = c(0,which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt])))
     
     
        for (j in 1:length(komusmult[-fragen])) {
            if (j %in% multifragen) {
                fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
            } else {
                fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
            }
        }
        <<fitting>>





        if (length(multifragen) == 1) {
        chances = lapply(fitting, predict, komusmult[k,], type="response")
        Entropietemp = chances
        Entropietemp = lapply(chances, FUN.Entropie)
        Entropietemp = simplify2array(Entropietemp)

} else {
        multifragen = multifragen[2:length(multifragen)]
        chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[k,], type="response")
        chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[k,], type="probs")
        Entropietemp = chances
#print(chances)
### Funktion kann nicht benutzt werden, da sie auf nicht manipulierte multifragen zugreift
        Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC.IND)
        Entropietemp[-multifragen] = lapply(chances[-multifragen], FUN.Entropie)
        Entropietemp = simplify2array(Entropietemp)}





#        chances = fitting
 #       chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[k,], type="response")
  #      chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[k,], type="probs")
   #     Entropietemp = chances

### Funktion kann nicht benutzt werden, da sie auf nicht manipulierte multifragen zugreift
 #       Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC.IND)
  #      Entropietemp[-multifragen] = lapply(chances[-multifragen], FUN.Entropie)
   #     Entropietemp = simplify2array(Entropietemp)

        Restentropietemp[items] = sum(Entropietemp)
    }
    multifragen = 0
    multifragen = c(multifragen,which(fragen %in% multifragenalt))
 





        if (length(multifragen) == 1) {
        chances = modell
        chances = lapply(modell, predict, komusmult[k,], type="response")
        Entropietemp = chances
        Entropietemp = lapply(chances, FUN.Entropie)
        Entropietemp = simplify2array(Entropietemp)

} else {
        multifragen = multifragen[2:length(multifragen)]
        chances = modell
        chances[-multifragen] = lapply(modell[-multifragen], predict, komusmult[k,], type="response")
        chances[multifragen] = lapply(modell[multifragen], predict, komusmult[k,], type="probs")
        Entropietemp = chances
#print(chances)
### Funktion kann nicht benutzt werden, da sie auf nicht manipulierte multifragen zugreift
        Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC.IND)
        Entropietemp[-multifragen] = lapply(chances[-multifragen], FUN.Entropie)
        Entropietemp = simplify2array(Entropietemp)}




#        chances = modell
#        chances[-multifragen] = lapply(modell[-multifragen], predict, komusmult[k,], type="response")
 #       chances[multifragen] = lapply(modell[multifragen], predict, komusmult[k,], type="probs")
  #      Entropietemp = chances

### Funktion kann nicht benutzt werden, da sie auf nicht manipulierte multifragen zugreift
   #     Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC.IND)
    #    Entropietemp[-multifragen] = lapply(chances[-multifragen], FUN.Entropie)
     #   Entropietemp = simplify2array(Entropietemp)




    return(c(Entropietemp, Restentropietemp))    
})

#Entropieall


#######
#    fragen = frageninit
#    for (i in 2:items) {
#        Entropietemp = NULL
#        fitting = NULL
# 
#        for (j in 1:length(komus[-fragen])) {
#            fitting[[j]] = glm(reformulate(names(komus[fragen]), names(komus[-fragen][j])), data = komus, family = "binomial"(link=logit))
#        }
#        <<fitting>>
#        chances = simplify2array(mclapply(fitting, predict, komus[k,], type="response"))
#        Restentropietemp[i-1] = sum(-chances*log(chances,2)-(1-chances)*log(1-chances,2)) 
#        Entropietemp = (-chances*log(chances,2)-(1-chances)*log(1-chances,2))
#        fragen = c(fragen, which(names(komus[-fragen][which((Entropietemp) == max((Entropietemp)))]) == names(komus)))
#        modell[[i]] = fitting[[which((Entropietemp) == max((Entropietemp)))]]
#    }
# 
#    if (length(komus) == items) {
#        Restentropietemp[items] = 0
#    } else {
#        fitting = NULL
#        for (j in 1:length(komus[-fragen])) {
#            fitting[[j]] = glm(reformulate(names(komus[fragen]), names(komus[-fragen][j])), data = komus, family = "binomial"(link=logit))
#        }
#        <<fitting>>
#        chances = simplify2array(lapply(fitting, predict, komus[k,], type="response"))
#        Restentropietemp[length(fragen)] = sum(-chances*log(chances,2)-(1-chances)*log(1-chances,2))
#    }
# 
#    chances = simplify2array(mclapply(modell, predict, komus[k,], type="response"))
#    Entropietemp = (-chances*log(chances,2)-(1-chances)*log(1-chances,2))
# 
#    return(c(Entropietemp, Restentropietemp))
#})

Restentropietemp = (Entropieall[(items+1):(items*2),])
Entropieall = Entropieall[1:items,]
 
SumSDtemp = sd(Entropieall[1,])
for (i in 2:length(Entropieall[,1])) {
SumSDtemp[i] = sd(colSums(Entropieall[1:i,]))
}
 
SumSD$indivbedsort = c(0,SumSDtemp)
EEE$indivbedsort = c(0,rowMeans(Entropieall))
RestEntropie$indivbedsort = c(0,rowMeans(Restentropietemp))
RestEntropieSD$indivbedsort = c(0,apply(Restentropietemp, 1, sd))

multifragen = multifragenalt
EEE
SumSD
RestEntropie
RestEntropieSD
#+END_SRC

#+RESULTS:
#+begin_example
   kill indivbedsort
1    NA    0.0000000
2    NA    2.7217770
3    NA    2.4496175
4    NA    2.1644492
5    NA    1.8783694
6    NA    1.4879522
7    NA    1.0409599
8    NA    1.0013870
9    NA    0.9995325
10   NA    0.9991734
11   NA    0.9984890
12   NA    0.9994329
13   NA    0.9966256
14   NA    0.9978136
15   NA    0.9952600
16   NA    0.9946178
17   NA    0.9932245
18   NA    0.9886792
19   NA    0.9960079
20   NA    0.9806688
21   NA    0.9681367
   kill indivbedsort
1    NA   0.00000000
2    NA   0.00000000
3    NA   0.04136783
4    NA   0.05698899
5    NA   0.17801488
6    NA   0.41017857
7    NA   0.41321094
8    NA   0.41490825
9    NA   0.41456487
10   NA   0.41489563
11   NA   0.41454711
12   NA   0.41441137
13   NA   0.41303384
14   NA   0.41211814
15   NA   0.41292608
16   NA   0.41288518
17   NA   0.40706872
18   NA   0.40560736
19   NA   0.40824918
20   NA   0.43043538
21   NA   0.46509936
   kill indivbedsort
1    NA      0.00000
2    NA     51.23638
3    NA     47.65006
4    NA     43.52579
5    NA     41.29864
6    NA     39.47712
7    NA     38.49392
8    NA     36.70485
9    NA     35.21624
10   NA     34.21357
11   NA     32.84669
12   NA     31.59166
13   NA     30.38413
14   NA     29.11120
15   NA     27.69721
16   NA     26.21735
17   NA     24.91548
18   NA     24.10171
19   NA     22.70520
20   NA     21.71047
21   NA     20.65227
   kill indivbedsort
1    NA     0.000000
2    NA     0.753034
3    NA     2.051872
4    NA     3.265273
5    NA     2.709120
6    NA     2.527263
7    NA     3.013739
8    NA     3.153381
9    NA     3.322234
10   NA     3.198944
11   NA     3.544405
12   NA     3.509632
13   NA     3.625651
14   NA     3.891570
15   NA     3.757511
16   NA     3.626518
17   NA     3.564043
18   NA     3.326500
19   NA     3.526391
20   NA     3.526394
21   NA     3.904485
#+end_example

**** Schlussberechnungen
#+NAME: statisticend
#+BEGIN_SRC R :session stat :exports both :results output :noweb yes
    if (names(EEE[1]) == 'kill') {
        EEE = EEE[-1]
    }
    
    if (names(SumSD[1]) == 'kill') {
        SumSD = SumSD[-1]
    }
    
    if (names(RestEntropie[1]) == 'kill') {
        RestEntropie = RestEntropie[-1]
        RestEntropieSD = RestEntropieSD[-1]
    }
    
    for (i in 1:length(EEE[1,])) {
        for (j in 1:length(EEE[,1])) {
            summe[j,i] = sum(EEE[1:j,i])
        }
    }
    
    fitting = NULL
    multifragen = multifragenalt
    for (i in 1:length(komusmult)) {
        if (i %in% multifragen) {
            fitting[[i]] = polr(reformulate('1', names(komusmult[i])), data = komusmult)
        } else {
            fitting[[i]] = glm(reformulate('1', names(komusmult[i])), data = komusmult, family = "binomial"(link=logit))
        }
    }
    
    chances = fitting
    chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[1,], type="response")
    chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[1,], type="probs")
    Entropietemp = FUN.Entropietemp.IND(chances)
    RestEntropie[1,] = sum(Entropietemp)
    
    names(summe) = names(EEE)
    
    if (exists("benchmark")) {
        benchmark = array(c(benchmark,(proc.time() - calculationtime)[3]))
    } else {
        benchmark = (proc.time() - calculationtime)[3]
    }
    
    benchmark
#+END_SRC

#+RESULTS: statisticend
#+begin_example
   indivbedsort  bedunsort   sortbed durchschbedsort
1   0.000000000 0.00000000 0.0000000       0.0000000
2   0.000000000 0.00000000 0.0000000       0.0000000
3   0.009027186 0.03612246 0.1983181       0.1983181
4   0.058175471 0.12307861 0.1836646       0.1836646
5   0.036887934 0.15193926 0.3081664       0.3081664
6   0.249079208 0.17241318 0.4343293       0.4343293
7   0.248986880 0.20682939 0.4509517       0.4509517
8   0.251734351 0.24237949 0.5067252       0.4462344
9   0.251355632 0.25881748 0.5616286       0.4712818
10  0.251850701 0.31256855 0.6229583       0.4734396
11  0.252317169 0.33410530 0.7341474       0.4936977
12  0.252293466 0.33998027 0.7624061       0.6219635
13  0.251128547 0.39125557 0.8113207       0.6976255
14  0.250552701 0.42975794 0.8185915       0.7790595
15  0.248486026 0.42349509 0.8558938       0.7594151
16  0.245221906 0.41640116 0.9172812       0.8187282
17  0.237280890 0.47215671 1.0047197       0.8861457
18  0.224736273 0.51339028 1.0465661       0.9575355
19  0.222729805 0.61657818 1.1358562       1.0109329
20  0.213474477 0.63785506 1.2148806       1.0802093
21  0.202864938 0.62495496 1.3352945       1.1127404
22  0.181967838 0.65893403 1.3609576       1.1800977
23  0.162761475 0.67866387 1.3765599       1.2096190
24  0.137173282 0.68723070 1.4425431       1.2781875
25  0.116580339 0.76895208 1.4766355       1.3214731
26  0.096995491 0.92560835 1.5702236       1.4114624
27  0.099342419 0.96951616 1.5776008       1.4911603
28  0.084862541 1.03780185 1.6523345       1.5725229
29  0.126204239 1.03776856 1.6894748       1.6359801
30  0.243648348 1.11254469 1.7426779       1.7087325
31  0.385627284 1.12987241 1.7820840       1.7288287
32  0.530251300 1.12426329 1.8406915       1.8341731
33  0.650850438 1.09454820 1.9058400       1.9079640
34  0.769100466 1.17885499 1.9539438       1.9704312
35  0.916306970 1.20383285 1.9998765       1.9511185
36  1.021972354 1.27793894 2.0688776       2.0022737
37  1.116760468 1.32870822 2.1269316       2.0376889
38  1.250866440 1.31232738 2.1630571       2.0788161
39  1.289650757 1.32453015 2.1369154       2.1049176
40  1.329302019 1.37955080 2.2783350       2.1798824
41  1.434448147 1.39687941 2.2884582       2.2254375
42  1.559052828 1.52166070 2.3447304       2.2857543
43  1.619351077 1.57043988 2.4397638       2.3484066
44  1.683992073 1.73187200 2.4672003       2.4331340
45  1.713294697 1.75381895 2.5229130       2.5017589
46  1.833789948 1.81696497 2.5829531       2.4879525
47  1.922849626 1.85320896 2.6477066       2.5155152
48  2.040543021 1.87138487 2.7164187       2.5680999
49  2.133639668 1.87809328 2.7454682       2.6726378
50  2.202070286 1.90631726 2.7680102       2.7372880
51  2.300427561 1.92609908 2.7994667       2.7921903
52  2.315507271 1.96181017 2.8620420       2.8555011
53  2.313326081 1.98866202 2.9048580       2.9078619
54  2.317056723 2.01926181 2.9048583       2.9078623
55  2.317055596 2.04300519 2.9048580       2.9078619
[1]   70.721  228.130  383.466  819.515 1034.967 1083.324 1144.432 1196.436
[9] 1225.932
#+end_example

**** Formel für die Modellanpassung
#+NAME: fitting
#+BEGIN_SRC R
#fitting = mclapply(fitting, step, trace = 0)
#fitting = mclapply(fitting, step, ~.^2, trace = 0)
#+END_SRC

**** Benchmark
#+BEGIN_SRC R :session stat :noweb yes :results output graphics :file /images/benchmark.png :exports both
plot(benchmark, type="l", col=rgb(0,0,0), ann=F)
title(xlab="Durchlauf")
title(ylab="Dauer")
#+END_SRC

#+RESULTS:
[[file:/images/benchmark.png]]

**** Entropiegrafik
#+NAME: grafik
#+BEGIN_SRC R :session stat :noweb yes :results output graphics :file /images/entropie2.png :exports both
    <<statistic>>
    <<statistic1>>
    <<statistic2>>
    <<statistic3>>
    <<statistic4>>
    <<statisticend>>
    
    farbe = NULL
    farbeSD = NULL
    for (j in 1:(length(summe[1,]))) {
        r = runif(1,0.1,0.9)
        g = runif(1,0.1,0.9)
        b = runif(1,0.1,0.9)
        farbe[j] = rgb(r^1.2, g^1.2, b^1.2)
        farbeSD[j] = rgb(sqrt(r), sqrt(g), sqrt(b))
    }
    
    plot(0:(length(komusmult)), type="l", col=rgb(0,0,0), ann=F)
    for (i in 1:(length(summe[1,]))) {
        lines(summe[,i], col=farbe[i])
        if (dim(SumSD[names(SumSD) == names(summe[i])])[2] != 0) {
            lines(summe[,i]+SumSD[names(summe[i])],lty = 4, col=farbeSD[i])
            lines(summe[,i]-SumSD[names(summe[i])],lty = 4, col=farbeSD[i])
        }
        if (dim(RestEntropie[names(RestEntropie) == names(summe[i])])[2] != 0) {
            lines(RestEntropie[names(summe[i])], col=farbe[i])
            lines(RestEntropie[names(summe[i])]+RestEntropieSD[names(summe[i])],lty = 4, col=farbeSD[i])
            lines(RestEntropie[names(summe[i])]-RestEntropieSD[names(summe[i])],lty = 4, col=farbeSD[i])
        }
    }
    
    title(xlab="Anzahl der beantworteten Fragen")
    title(ylab="Entropie in bit")
    legend(length(komusmult)/4, length(komusmult), c(names(summe), round(benchmark[length(benchmark)])), cex=0.9, col=c(farbe, rgb(1,1,1)), lty=1);
#+END_SRC

#+RESULTS: grafik
[[file:/images/entropie2.png]]
     
