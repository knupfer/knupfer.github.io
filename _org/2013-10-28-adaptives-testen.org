#+BEGIN_COMMENT
---
layout: post
title: Adaptives Testen
father: Wissenschaft
---
#+END_COMMENT
Beim adaptiven Testen werden die Möglichkeiten einer computerbasierten Testung in erweitertem Maße ausgenutzt.
Es wird innerhalb der Testung auf Grund der bereits beantworteten Fragen auf den Fähigkeitsgrad des Probanden geschätzt, um ihm als nächstes eine Frage zu geben, die diesen reflektiert.

#+BEGIN_SRC ditaa :file /images/adaptiveditaa.png :exports results
+---------+   +--------+   +---------------+
|  Item-  |-->| Modell |-->|   Schätzung   |
| antwort |   +--------+   | nächstes Item |
+---------+                +-------+-------+
    ^                              |
    |                              |
    +------------------------------+
#+END_SRC

* Kriterien
Wie genau die Frage ausgewählt wird hängt vornehmlich von den Zielen der Testung und den Nebenwirkungen, die man ggf. vermeiden möchte, ab.
So wäre eine Frage, die der Proband mit einer Chance von 50% lösen kann ideal im Sinne eines Informationsgewinnes über den Probanden, da die Entropie maximal ist.

Entropie stellt nicht nur Chaos, sondern auch Informationsdichte nach Shannon dar (vgl. [[http://de.wikipedia.org/wiki/Entropie_%28Informationstheorie%29][Wikipedia]]).
Die folgende Formel ergiebt die Entropie eines Ereignisses. Hierbei ist $n$ die Anzahl der Möglichkeiten und $p_i$ die jeweiligen Wahrscheinlichkeiten dieser (sich ausschließender) Möglichkeiten.
    $$ H = - \sum_{i=1}^n p_i \cdot \log_2{p_i} $$

Betrachten wir ein binäres System, also nur Fragen die entweder vollständig falsch oder vollständig richtig beantwortet werden können, so haben wir $n = 2$ und $p_2 = 1 - p_1$.
$$ H_2 = - p \cdot \log_2{p} - (1 - p) \cdot \log_2(1 - p) $$

Hieraus ergiebt sich, dass der Informationsgewinn bei $p = .5$ (im binären) maximal ist, da die Funktion symmetrisch ist und bei $p = 0$ auf beiden Seiten $0$ ergibt.
$$ H_{max} = - 0.5 \cdot \log_2{0.5} - 0.5 \cdot \log_2{0.5} = 1 \mathrm{bit} $$

Hierbei ist $bit$ die übliche Einheit des Informationsgehaltes, auf Grund des $\log_2$. Es kann also ein Informationsgehalt von 8 bit mit Hilfe eines bytes dargestellt werden, sprich mit 8 Nullen oder Einsen (z.B. 10101010).

#+BEGIN_SRC R :results output graphics :file /images/entropie.png :exports results
x = (0:100)/100
y = -x*log(x,2)-(1-x)*log(1-x,2)
plot(x,y,type="l",xlab=expression(Lösungswahrscheinlichkeit),ylab=expression("Entropie in bit"),  main="Entropieverteilung")
#+END_SRC

#+RESULTS:
[[file:/images/entropie.png]]

Mit der Formel für tatsächliche und für maximale Entropie kann die Redundanz ausgerechnet werden, welche in einer Testkonstruktion als Indikator für das Potential der Verbesserung durch ein adaptives Testverfahren benutzt werden kann.
$$ R = H_{max} - H $$

Somit kann im binären ein Test im idealfall um $R$ Fragen verkleinert werden, ohne an Informationen einzubüßen.
Befinden sich im Test auch Fragen, die nicht binär sind, so verändert sich die Situation ein wenig.
Die Entropie wird stets maximal bei gleichen Wahrscheinlichkeiten.
Gibt es nun bei einer Frage z.B. 0, 1, 2 oder 3 Punkte gibt es eine maximale Entropie von $H_{max} = - \log_2{0.25} = 2 \mathrm{bit}$. Somit kann man einen Test auch um $R/2$ solcher Fragen ohne Informationsverlust verkleinern.

** Informationsgehalt in KoMus
Im August diesen Jahres habe ich mit Teilen des KoMus-Testes für musikalische Kompetenz eine empirische Studie durchgeführt.
Der KoMus-Test liegt in einem nicht adaptiven Format vor.

Interessant ist nun, die Überlegung, wieviel der Test von einer Überführung in einen adaptiven Test profitieren würde.

*** Durchschnittlicher Schüler
Der Simplizität halber können wir annehmen, dass ein Schüler genau die durchschnittlichen Lösungswahrscheinlichkeiten für ein Item aufweist.
So muss man nur die Entropie mit den klassischen Itemschwierigkeiten der Items berechnen:
$$ H = \sum_{i=1}^n(- P_i \cdot \log_2{P_i} - (1 - P_i) \cdot \log_2(1 - P_i)) $$

Hierbei ist $P_i$ die klassische Itemschwierigkeit des Items $i$ und $n$ die Anzahl der Items.
Ferner nimmt diese Formel nur dichotome Items an.

*** Vierdimensional
Die Entropie ist jedoch eigentlich noch niedriger, wenn man die Schwierigkeiten adaptiv berechnet. 
Es handelt sich aber immernoch um einen nicht adaptiven Test mit fester Reihenfolge. Es wird nur eine spezialform der Entropie, die bedingte Entropie, benutzt (vgl. [[http://de.wikipedia.org/wiki/Bedingte_Entropie][Wikipedia]]).

Um die bedingte Lösungschance und somit auch die bedingte Entropie zu berechnen, werden alle Items der selben Dimension einer logistisch binären Regression verwendet um die individuell Itemschwierigkeit eines Items der gleichen Dimension zu berechnen.
$$ H = \sum_{D=1}^4(\sum_{i=1}^{n(D)}(- R \cdot \log_2{R}) - (1 - R) \cdot \log_2(1- R))$$
$$ R = Reg_2(P_{ivD}|\sum_{m=1}^{i(D)-1}P_{vmD}) $$

Hierbei ist $Reg_2(a|b)$ die binärlogistische Regression mit der AV $a$ und den UV $b$.

*** n-Dimensional
Das obige Modell nimmt jedoch an, dass die einzelnen Dimensionen nicht korrelieren und somit Itemantworten einer Dimension keine Information (also Entropiesenkung) über andere Dimensionen zulassen.

Dies ist aber eine nicht notwendige Einschränkung, die die Berechnung nicht nur weniger effektiv, sondern auch komplizierter macht.

Berücksichtigen wir unabhängig von der Dimensionszugehörigkeit einfach alle bereits beantworteten Items, die einen signifikanten Einfluss auf die Frage haben, haben wir im Endeffekt ein n-dimensionales Modell, wobei $n$ die Anzahl der Fragen ist.
$$ H = \sum_{i=1}^n(- R \cdot \log_2{R} - (1 - R) \cdot \log_2(1 - R)) $$
$$ R = Reg_2(P_{iv}|\sum_{m=1}^{i-1}P_{vm}) $$

**** Probleme
Mögliche Probleme dieser Methode sind fehlende Datensätze, da die binärlogistische Regression normalerweise alle Fälle ausschließt, die auch nur bei einem der UV keinen Wert hat.
Durch den maßgeschneiderten Testweg ist es bei einem Itempool, der nicht komplett erschöpft wird, unmöglich diese Regression so durchzuführen.
Dementsprechend müssen andere Methoden gewählt werden, um mit fehlenden Daten umzugehen.

Eine Möglichkeit wäre, nicht vorhandene Antworten in den Datensätzen zu simulieren.
Diese Simulation würde von den Items die am sichersten geschätzt werden können zu den Items, die schwer geschätzt werden können stattfinden.

Der Grund hierfür liegt daran, dass bei einer sehr sicheren Schätzung der Entropiegehalt sich nur wenig ändert, aber es gleich viel mehr Personen gibt, die seriös für schwerere Schätzungen verwendet werden können, was diese Schätzungen erleichtert.

Die Simulation sollte nach jeder Testung durchgeführt werden, um die Simulation mehr und mehr zu verbessern.
Das dieses Verfahren direkt einen Nutzen erbringt, sollte daran sichtbar sein, dass die Lösungen der alten Datensätze immer besser retrospektiv vorhergesagt werden können und somit davon außgegangen werden kann, dass auch bei aktuellen Testungen die Schätzungen besser sind und somit effektiver gemessen werden kann.

* Umsetzung
Die Umsetzung wurde mit R bewerkstelligt. Hier traten auch schnell Probleme auf.
So wurde die Rechenzeit bei etwas komplizierteren Modellen sehr lang, was natürlich auch an meinem Computer liegt.
Nichts desto trotz ergaben sich Situationen, in denen der Computer 5 Tage lang rechnen hätte müssen.

In anderen Situationen wurde das komplette Ram des Computers aufgezehrt usw.

** Programmierung

*** Initialisierung

Für alle nachfolgenden Berechnungen habe ich immer dieses Skript benutzt, um grundlegende Dinge, wie Funktionen, die an vielen Stellen benötigt werden, die Daten usw. bereitgestellt werden.
Ferner werden, wo möglich, Berechnungen mit dieser Initialisierung parallelisiert.

#+NAME: statistic
#+BEGIN_SRC R :exports code :results none :noweb yes
require(MASS)
library(multicore)
library(foreach)
library(doMC)
registerDoMC(3)

calculationtime <- proc.time()
komus = read.table("data/data_komus_bin2.dat",header=TRUE)
test = data.frame(read.table("data/komus.csv",header=TRUE, sep=','))
pcitems = array(which(sapply(test, max) > 1))
pcitemsalt = pcitems
test[pcitems] = lapply(test[pcitems],factor)

FUN.infoMC = function(x) {return(rowSums(-x*log(x+0.00000001, 2)))}
FUN.infoMC.IND = function(x) {return(sum(-x*log(x+0.00000001, 2)))}
FUN.info = function(x) {return(-x*log(x+0.000001, 2)-(1-x)*log(1-x+0.00001, 2))}
FUN.Odds = function(x) {
    if (length(pcitems) > 0) {
        x[-pcitems] = lapply(x[-pcitems], predict, type="response")
        x[pcitems] = lapply(x[pcitems], predict, type="probs")
    } else {
        x = lapply(x, predict, type="response")
    }
    return(x)
}
FUN.Odds.IND = function(x,y) {
    x[-pcitems] = lapply(x[-pcitems], predict, data = test[y,], type="response")
    x[pcitems] = lapply(x[pcitems], predict, data = test[y,], type="probs")
    return(x)
}
FUN.infotemp = function(x) {
    if (length(pcitems) > 0) {
        x[pcitems] = lapply(x[pcitems], FUN.infoMC)
        x[-pcitems] =lapply(x[-pcitems], FUN.info)
    } else {
        x =lapply(x, FUN.info)
    }
    x = simplify2array(x)
    return(x)
}
FUN.infotemp.IND = function(x) {
    if (length(pcitems) > 0) {
        x[pcitems] = lapply(x[pcitems], FUN.infoMC.IND)
        x[-pcitems] =lapply(x[-pcitems], FUN.info)
    } else {
        x =lapply(x, FUN.info)
    }
    x = simplify2array(x)
    return(x)
}
FUN.EntroMC = function(funpcitems, fundata, funmod) {

    if (length(funpcitems) == 1) {
        odds = lapply(funmod, predict, fundata, type="response")
        infotemp = odds
        infotemp = lapply(odds, FUN.info)
        infotemp = simplify2array(infotemp)
    } else {
        funpcitems = funpcitems[2:length(funpcitems)]
        odds = funmod
        odds[-funpcitems] = lapply(funmod[-funpcitems], predict, fundata, type="response")
        odds[funpcitems] = lapply(funmod[funpcitems], predict, fundata, type="probs")
        infotemp = odds

        infotemp[funpcitems] = lapply(odds[funpcitems], FUN.infoMC.IND)
        infotemp[-funpcitems] = lapply(odds[-funpcitems], FUN.info)
        infotemp = simplify2array(infotemp)
    }
    return(infotemp)
}






info = NULL
odds = NULL
fit = NULL
modell = NULL
summe = data.frame()
############
items = length(test)
#persons = length(test[,1])
#items = 50
persons = 3
############

EEE = data.frame(matrix(ncol = 1, nrow = items+1))
SumSD = data.frame(matrix(ncol = 1, nrow = items+1))
Restinfo = data.frame(matrix(ncol = 1, nrow = items+1))
RestinfoSD = data.frame(matrix(ncol = 1, nrow = items+1))
names(EEE) = 'kill'
names(SumSD) = 'kill'
names(Restinfo) = 'kill'
names(RestinfoSD) = 'kill'
#+END_SRC

*** Nichtadaptiv
**** Unbedingte und bedingte info in normaler Reihenfolge
Dieser verhältnismäßig simple Code berechnet die info über die klassische Itemschwierigkeit und die info über die durch binär-logistische Regressionen vorhergesagte Itemschwierigkeit in der ursprünglichen Reihenfolge.
Zudem wird bei zweiter Berechnung noch angegeben, wie viel Restentropie nach jeder Antwort noch zu erwarten ist.
#+NAME: statistic1
#+BEGIN_SRC R :exports code :results output :noweb yes
modell = NULL

pcitems = pcitems[pcitems <= items]
if (1 %in% pcitems) {
    modell[[1]] = polr(reformulate('1', names(test[1])), data = test)
} else {
    modell[[1]] = glm(reformulate('1', names(test[1])), data = test, family = "binomial"(link=logit))
}

for (i in 2:items) {
    if (i %in% pcitems) {
        modell[[i]] = polr(reformulate(names(test[1:i-1]), names(test[i])), data = test)
    } else {
        modell[[i]] = glm(reformulate(names(test[1:i-1]), names(test[i])), data = test, family = "binomial"(link=logit))
    }
}

fit = modell
<<fit>>
    odds = FUN.Odds(fit)

infotemp = FUN.infotemp(odds)

### Without relations ###
fit = lapply(fit, update, ~ 1)
odds2 = FUN.Odds(fit)

infotemp2 = FUN.infotemp(odds2)

pcitems = pcitemsalt

query = NULL
resttemp = NULL
for (i in 1:items) {
    infotemp3 = NULL
    fit3 = NULL
    if (i == length(test)) {
        resttemp[[i]] = resttemp[[1]]*0
    } else {
        query = 1:i
        pcitems = which(names(test[-query]) %in% names(test[pcitemsalt]))

        for (j in 1:length(test[-query])) {
            if (j %in% pcitems) {
                fit3[[j]] = polr(reformulate(names(test[query]), names(test[-query][j])), data = test)
            } else {
                fit3[[j]] = glm(reformulate(names(test[query]), names(test[-query][j])), data = test, family = "binomial"(link=logit))
            }
        }
        <<fit>>
            odds3 = FUN.Odds(fit3)

        infotemp3 = FUN.infotemp(odds3)
        resttemp[[i]] = rowSums(infotemp3)
    }
}

resttemp = simplify2array(resttemp)

Restinfo$bedunsort = c(0,colMeans(resttemp))
RestinfoSD$bedunsort = c(0,apply(resttemp, 2, sd))



SumSDtemp = sd(infotemp[,1])
for (i in 2:length(infotemp[1,])) {
    SumSDtemp[i] = sd(rowSums(infotemp[,1:i]))
}

SumSD$bedunsort = c(0,SumSDtemp)

EEE$bedunsort = c(0,colMeans(infotemp))
EEE$unbedunsort = c(0,colMeans(infotemp2))
EEE$unbedsort = c(0,sort(colMeans(infotemp2), decreasing =TRUE))
infotemp2 = data.frame(infotemp2)
names(infotemp2) = names(test[1:length(infotemp2)])
EEE
Restinfo
#+END_SRC

**** Bedingte, sortierte info
Hier werden die Items schlicht nach dem durchschnittlichen infogehalt sortiert, bevor die bedingte info mit Regressionen berechnet wird.
Dies verbessert die resultierende Kurve schon um einiges, der infogewinn ist so tendenziell am Anfang weit höher als am Ende, trotz dass gleich viel info innerhalb des kompletten Durchlaufes ermittelt wurde.
#+NAME: statistic2
#+BEGIN_SRC R :exports code :results output :noweb yes
modell = NULL
odds = NULL
fit = NULL

############## sortierte Reihenfolge
for (i in 1:items) {
    if (i %in% pcitems) {
        modell[[i]] = polr(reformulate('1', names(test[i])), data = test)
    } else {
        modell[[i]] = glm(reformulate('1', names(test[i])), data = test, family = "binomial"(link=logit))
    }
}

odds = FUN.Odds(modell)
infotemp = FUN.infotemp(odds)
infotemp = data.frame(infotemp)
names(infotemp) = names(test[1:length(infotemp)])
komus2 = test[c(names(sort(colMeans(infotemp), decreasing=TRUE)))]
#########

names(sort(colMeans(infotemp), decreasing=TRUE))
pcitems.alt = pcitems
pcitems.alt
pcitems = which(names(komus2) %in% names(test[pcitems.alt]))
modell = NULL
fit = NULL
odds = NULL

if (1 %in% pcitems) {
    modell[[1]] = polr(reformulate('1', names(komus2[1])), data = komus2)
} else {
    modell[[1]] = glm(reformulate('1', names(komus2[1])), data = komus2, family = "binomial"(link=logit))
}

for (i in 2:items) {
    if (i %in% pcitems) {
        modell[[i]] = polr(reformulate(names(komus2[1:i-1]), names(komus2[i])), data = komus2)
    } else {
        modell[[i]] = glm(reformulate(names(komus2[1:i-1]), names(komus2[i])), data = komus2, family = "binomial"(link=logit))
    }
}

fit = modell
<<fit>>
odds = FUN.Odds(fit)
#odds[-pcitems] = mclapply(fit[-pcitems], predict, type="response")
#odds[pcitems] = mclapply(fit[pcitems], predict, type="probs")

#infotemp = fit
infotemp = FUN.infotemp(odds)
#infotemp[pcitems] = lapply(odds[pcitems], FUN.infoMC)
#infotemp[-pcitems] =lapply(odds[-pcitems], FUN.info)
#infotemp = simplify2array(infotemp)

SumSDtemp = sd(infotemp[,1])
for (i in 2:length(infotemp[1,])) {
    SumSDtemp[i] = sd(rowSums(infotemp[,1:i]))
}

SumSD$sortbed = c(0,SumSDtemp)

EEE$sortbed = c(0,colMeans(infotemp))

pcitems = pcitems.alt
#+END_SRC

**** Durchschnittlich bedingtsortierte info
Dieses Verfahren ist bereits weit rechenintensiver, es wird nacheinander das Item ausgewählt, welches durchschnittlich die info am meisten senkt.
Es wird also nach der Erfassung eines Items dieses miteinbezogen für kommende Regressionen.
Insgesamt ist dies aber noch nicht individualisiert und dementsprechen nicht adaptiv.
#+NAME: statistic3
#+BEGIN_SRC R :exports code :results output :noweb yes
query = NULL
modell = NULL
resttemp = NULL
pcitemsalt = pcitems
############## sortierte Reihenfolge
for (i in 1:length(test)) {
    if (i %in% pcitems) {
        fit[[i]] = polr(reformulate('1', names(test[i])), data = test)
    } else {
        fit[[i]] = glm(reformulate('1', names(test[i])), data = test, family = "binomial"(link=logit))
    }
}
#modell
odds = FUN.Odds(fit)

infotemp = FUN.infotemp(odds)

query = which(names(test[which(colMeans(infotemp) == max(colMeans(infotemp)))[1]]) == names(test))[1]
query
#########
modell[[1]] = fit[[query]]

for (i in 2:items) {
    infotemp = NULL
    fit = NULL

    pcitems = which(names(test[-query]) %in% names(test[pcitemsalt]))

    for (j in 1:length(test[-query])) {
        if (j %in% pcitems) {
            fit[[j]] = polr(reformulate(names(test[query]), names(test[-query][j])), data = test)
        } else {
            fit[[j]] = glm(reformulate(names(test[query]), names(test[-query][j])), data = test, family = "binomial"(link=logit))
        }
    }
    <<fit>>
    odds = FUN.Odds(fit)

    infotemp = FUN.infotemp(odds)
    resttemp[[i-1]] = rowSums(infotemp)

    query = c(query, which(names(test[-query][which(colMeans(infotemp) == max(colMeans(infotemp)))[1]]) == names(test))[1])
    modell[[i]] = fit[[which(colMeans(infotemp) == max(colMeans(infotemp)))[1]]]
}

if (length(test) == items) {
    resttemp[[items]] = resttemp[[1]]*0
} else {
    fit = NULL

    pcitems = which(names(test[-query]) %in% names(test[pcitemsalt]))

    for (j in 1:length(test[-query])) {
        if (j %in% pcitems) {
            fit[[j]] = polr(reformulate(names(test[query]), names(test[-query][j])), data = test)
        } else {
            fit[[j]] = glm(reformulate(names(test[query]), names(test[-query][j])), data = test, family = "binomial"(link=logit))
        }
    }
    <<fit>>
    odds = FUN.Odds(fit)
    infotemp = FUN.infotemp(odds)
    resttemp[[items]] = rowSums(infotemp)
}
pcitems = which(query %in% pcitemsalt)

resttemp = simplify2array(resttemp)

odds = FUN.Odds(modell)
infotemp = FUN.infotemp(odds)

SumSDtemp = sd(infotemp[,1])
for (i in 2:length(infotemp[1,])) {
SumSDtemp[i] = sd(rowSums(infotemp[,1:i]))
}

SumSD$durchschbedsort = c(0,SumSDtemp)
EEE$durchschbedsort = c(0,colMeans(infotemp))
Restinfo$durchschbedsort = c(0,colMeans(resttemp))
RestinfoSD$durchschbedsort = c(0,apply(resttemp, 2, sd))
#+END_SRC

*** Adaptiv
**** Individuellbedingtsortierte info
Hier wird das zuletzt genannte Verfahren individualisiert, was den Rechenaufwand in diesem Fall 319 mal höher macht.
Das Ergebniss ist jedoch bereits ein echt adaptiver Test.
Somit ist die infokurve nun auch viel stärker gekrümmt (hat also eine größere zweite Ableitung).
Somit kann unter kleinem Informationsverlust der Test stark verkürzt werden.

Ideal wäre ein Itempool, der nicht komplett erschöpft wird in einer Testung. Somit könnte man berechnen, wie lang ein nichtadaptiver im Vergleich zu einem gleichpräzisen adaptiven Test ist.
#+NAME: statistic4
#+BEGIN_SRC R :exports code :results output :noweb yes
## initializing
infoall = NULL
odds = NULL
resttemp = NULL
query = NULL
modell = NULL
resttemp = NULL
pcitems = pcitemsalt
fit = NULL

## first item
for (i in 1:length(test)) {
    if (i %in% pcitems) {
        fit[[i]] = polr(reformulate('1', names(test[i])), data = test)
    } else {
        fit[[i]] = glm(reformulate('1', names(test[i])), data = test, family = "binomial"(link=logit))
    }
}

odds = fit
odds[-pcitems] = lapply(fit[-pcitems], predict, test[1,], type="response")
odds[pcitems] = lapply(fit[pcitems], predict, test[1,], type="probs")
infotemp = FUN.infotemp.IND(odds)
query = which(names(test[which(infotemp == max(infotemp))[1]]) == names(test))[1]

modell[[1]] = fit[[query]]
queryinit = query
fit = NULL

## multicorecalculation for every person
infoall = simplify2array(foreach(k=1:persons) %dopar% {
    query = queryinit
    Restentropie = NULL
    for (i in 2:items) {
        odds = NULL
        infotemp = NULL
        fit = NULL
        pcitems = c(0,which(names(test[-query]) %in% names(test[pcitemsalt])))
        for (j in 1:length(test[-query])) {
            if (j %in% pcitems) {
                fit[[j]] = polr(reformulate(names(test[query]), names(test[-query][j])), data = test)
            } else {
                fit[[j]] = glm(reformulate(names(test[query]), names(test[-query][j])), data = test, family = "binomial"(link=logit))
            }
        }

        <<fit>>
            odds = fit

        infotemp = FUN.EntroMC(pcitems,test[k,], fit)

        resttemp[i-1] = sum(infotemp) #rest of entropie before this item
        query = c(query, which(names(test[-query][which(infotemp == max(infotemp))[1]]) == names(test))[1])
        modell[[i]] = fit[[which(infotemp == max(infotemp))[1]]]
    }

    ## calculation of last rest entropie
    if (length(test) == items) {
        resttemp[items] = 0
    } else {
        fit = NULL
        pcitems = 0
        pcitems = c(0,which(names(test[-query]) %in% names(test[pcitemsalt])))
        for (j in 1:length(test[-query])) {
            if (j %in% pcitems) {
                fit[[j]] = polr(reformulate(names(test[query]), names(test[-query][j])), data = test)
            } else {
                fit[[j]] = glm(reformulate(names(test[query]), names(test[-query][j])), data = test, family = "binomial"(link=logit))
            }
        }
        <<fit>>

            infotemp = FUN.EntroMC(pcitems,test[k,], fit)
        resttemp[items] = sum(infotemp)
    }

    ## calculation of the choosen modell
    pcitems = c(0,which(query %in% pcitemsalt))

    infotemp = FUN.EntroMC(pcitems,test[k,], modell)
    return(c(infotemp, resttemp))
})

resttemp = (infoall[(items+1):(items*2),])
infoall = infoall[1:items,]

SumSDtemp = sd(infoall[1,])
for (i in 2:length(infoall[,1])) {
    SumSDtemp[i] = sd(colSums(infoall[1:i,]))
}

SumSD$indivbedsort = c(0,SumSDtemp)
EEE$indivbedsort = c(0,rowMeans(infoall))
Restinfo$indivbedsort = c(0,rowMeans(resttemp))
RestinfoSD$indivbedsort = c(0,apply(resttemp, 1, sd))

pcitems = pcitemsalt
#+END_SRC

**** Individuellbedingtsortierte info mit Trennschärfe
Ein nicht gut gelungener Versuch, nicht nur die info als Auswahlkriterium zu nehmen. Dies ist deswegen sinnvoll, da Items vorstellbar sind mit hoher info, die aber mit dem Test wenig zu tun haben (z.B. eine Frage nach der Schuhgröße hat vermutlich eine sehr hohe info, hat aber vermutlich wenig mit musikalischer Kompetenz zu tun).
Somit macht das bisherige Verfahren die Annahme, dass der Itempool sehr gut konstruiert ist.
Dementsprechend kann man das bisherige Verfahren sicher nicht als robust bezeichnen.
#+NAME: statistic5
#+BEGIN_SRC R :exports code :results output :noweb yes
infoall = NULL
odds = NULL
beta = NULL
resttemp = NULL
infotemp = NULL
fit = NULL

if (!exists("information")) {
    information = simplify2array(foreach(m=1:length(komus)) %dopar% {
        for (n in 1:(length(komus)-1)) {
            beta[[n]] = glm(reformulate(names(komus[m]), names(komus[-m][n])), data = komus, family = "binomial"(link=logit))
        }
        odds = simplify2array(lapply(beta, predict, type="response"))
        chancetemp = unlist(lapply(komus[m],mean))
        infotemp = (-odds*log(odds,2)-(1-odds)*log(1-odds,2))
        information = sum(colMeans(infotemp)) + (-chancetemp*log(chancetemp,2)-(1-chancetemp)*log(1-chancetemp,2))
        return(information)
    })
    information = -(information - sum(-colMeans(komus)*log(colMeans(komus),2)-(1-colMeans(komus))*log(1-colMeans(komus),2)))
}





for (j in 1:length(komus)) {
    fit[[j]] = glm(reformulate('1', names(komus[j])), data = komus, family = "binomial"(link=logit))
}
<<fit>>
odds = simplify2array(lapply(fit, predict, komus[1,], type="response"))
infotemp = (-odds*log(odds,2)-(1-odds)*log(1-odds,2)) + (information)
queryinit = which(names(komus[which((infotemp) == max((infotemp)))[1]]) == names(komus))[1]



modell[[1]] = fit[[which((infotemp) == max((infotemp)))[1]]]

infoall = simplify2array(foreach(k=1:persons) %dopar% {
    query = queryinit
    for (i in 2:items) {
        infotemp = NULL
        fit = NULL
        for (j in 1:length(komus[-query])) {
            fit[[j]] = glm(reformulate(names(komus[query]), names(komus[-query][j])), data = komus, family = "binomial"(link=logit))
        }

        <<fit>>
        ## TODO stimmt das so?
        odds = simplify2array(lapply(fit, predict, komus[k,], type="response"))
        resttemp[i-1] = sum(-odds*log(odds,2)-(1-odds)*log(1-odds,2)) 
        infotemp = (-odds*log(odds,2)-(1-odds)*log(1-odds,2)) + (information[-query]*(1 - (length(query)+1)/items))
        query = c(query, which(names(komus[-query][which((infotemp) == max((infotemp)))[1]]) == names(komus))[1])
        modell[[i]] = fit[[which((infotemp) == max((infotemp)))[1]]]
    }

    if (length(komus) == items) {
        resttemp[items] = 0
    } else {
        fit = NULL
        for (j in 1:length(komus[-query])) {
            fit[[j]] = glm(reformulate(names(komus[query]), names(komus[-query][j])), data = komus, family = "binomial"(link=logit))
        }
        <<fit>>
        odds = simplify2array(lapply(fit, predict, komus[k,], type="response"))
        resttemp[length(query)] = sum(-odds*log(odds,2)-(1-odds)*log(1-odds,2))
    }

    odds = simplify2array(lapply(modell, predict, komus[k,], type="response"))
    infotemp = (-odds*log(odds,2)-(1-odds)*log(1-odds,2))

    return(c(infotemp, resttemp))
})

resttemp = (infoall[(items+1):(items*2),])
infoall = infoall[1:items,]
SumSDtemp = sd(infoall[1,])
for (i in 2:length(infoall[,1])) {
SumSDtemp[i] = sd(colSums(infoall[1:i,]))
}

SumSD$indivbedsorttrenn = c(0,SumSDtemp )
EEE$indivbedsorttrenn = c(0,rowMeans(infoall))
Restinfo$indivbedsorttrenn = c(0,rowMeans(resttemp))
RestinfoSD$indivbedsorttrenn = c(0,apply(resttemp,1 ,sd))
#+END_SRC

**** Individuellbedingtsortierte info mit Prädiktion
Hier wird nun die info rekursiv berechnet.
Es wird nicht nur geschaut, welches Item die meiste info besitzt, sondern es werden für jedes Item alle Antwortmöglichkeiten simuliert und mit dieser Simulation die verbleibende info im gesamten Test errechnet, diese mit der Chance der simulierten Antwort gewichtet und aufaddiert mit den gewichteten anderen Antwortmöglichkeiten.

Dieses Modell umgeht also das Problem der vorherigen beiden.
Es ist sehr robust, weil immer auch berechnet wird, wie sehr sich das auserwählte Item mit all seinen Antwortmöglichkeiten auf die gesamte Restentropie auswirkt.
Dies ist eine mächtigere Form der Trennschärfe, weil sie nicht starr, sondern antwortmusterspezifisch ist.

Dieses Modell bringt die rechnerischen Anforderungen auf ein neues Niveau, sie werden nochmals ungefähr 30 mal höher.
Als Konsequenz daraus habe ich hier eine Datenbank mit implementiert, die einerseits bereits berechnetes speichert um mir wiederholte Arbeit zu ersparen und andererseits stets schaut, ob Frage-Antwort-Kombinationen bereits bei anderen Schülern vorgekommen ist, um mit Hilfe dieses Wissens hin und wieder einzelne Rechnungen zu ersparen.

Zunächst könnte man denken, dass es bei rund 50 binären Items $2^{50}$ Möglichkeiten der Antwortmuster gibt, was die Datenbank als sinnlos erscheinen lässt.
Jedoch muss bedacht werden, dass die Antwort Reihenfolge in der aktuellen Regression keine Rolle spielt. Beantwortet man Item a, b, und c richtig und bekommt daraufhin Item c, so würde man dies genauso bekommen, wenn man b, c und dann erst a richtig beantwortet, was die Sinnhaftigkeit der Datenbank deutlich steigert.
Zudem werden manche Antwortmuster und manche Items gehäuft vorkommen, weil sie entweder besonders qualitativ, oder besonders »normal« sind.
Im Moment fangen beispielsweise alle Schüler mit dem gleichen, maximal informativen Item an, weil noch keine Vorinformation über die Schüler vorhanden ist.
#+NAME: statistic6
#+BEGIN_SRC R :exports code :results output :noweb yes
## initializing
fit = NULL
infoall = NULL
odds = NULL
resttemp = NULL
query = NULL
modell = NULL
resttemp = NULL
pcitems = pcitemsalt

## first item
for (i in 1:length(test)) {
    if (i %in% pcitems) {
        fit[[i]] = polr(reformulate('1', names(test[i])), data = test)
    } else {
        fit[[i]] = glm(reformulate('1', names(test[i])), data = test, family = "binomial"(link=logit))
    }
}

odds = fit
odds[-pcitems] = lapply(fit[-pcitems], predict, test[1,], type="response")
odds[pcitems] = lapply(fit[pcitems], predict, test[1,], type="probs")
infotemp = FUN.infotemp.IND(odds)
query = which(names(test[which(infotemp == max(infotemp))[1]]) == names(test))[1]

modell[[1]] = fit[[query]]
queryinit = query
fit = NULL
Restentropie2 = NULL

## multicore calculation
infoall = simplify2array(foreach(k=1:persons) %dopar% {
    query = queryinit
    Restentropie = NULL
    resttemp2 = NULL
    resttemp = NULL
    for (i in 2:items) {
        odds = NULL
        infotemp = NULL
        fit = NULL
        fit2 = NULL
        fitplus = NULL
        fitminus = NULL
        infotemp2 = NULL
        pcitems = 0
        pcitems = c(pcitems,which(names(test[-query]) %in% names(test[pcitemsalt])))

        ## prediction for all not-answerd questions
        for (j in 1:length(test[-query])) {
            if (j %in% pcitems) {
                fit[[j]] = polr(reformulate(names(test[query]), names(test[-query][j])), data = test)
            } else {
                fit[[j]] = glm(reformulate(names(test[query]), names(test[-query][j])), data = test, family = "binomial"(link=logit))
            }

            ## prediction for all not-answered questions after prediction
            if (length(test[-query]) > 1) {
                pcitems2 = c(0,which(names(test[-query][-j]) %in% names(test[pcitemsalt])))
                for (n in 1:length(test[-query][-j])) {
                    if (n %in% pcitems2) {
                        fit2[[n]] = polr(reformulate(names(c(test[query], test[-query][j])), names(test[-query][-j][n])), data = test)
                    } else {
                        fit2[[n]] = glm(reformulate(names(c(test[query], test[-query][j])), names(test[-query][-j][n])), data = test, family = "binomial"(link=logit))
                    }
                }

                ## calculation of rest entropie for each possibility
                tempdata = test[k,]
                ##tempdata[-query][j] = 0 #dies muss noch bearbeitet werden (chancen...)
                <<fit>>
                    #                        odds = fit2
                    #                    if (length(pcitems2) == 1) {
                    #                        odds = lapply(fit2, predict, tempdata, type="response")
                    #                        infotemp = odds
                    #                        infotemp = lapply(odds, FUN.info)
                    #                        infotemp = simplify2array(infotemp)
                    #                    } else {
                    #                        pcitems2 = pcitems2[2:length(pcitems2)]
                    #                        odds[-pcitems2] = lapply(fit2[-pcitems2], predict, tempdata, type="response")
                    #                        odds[pcitems2] = lapply(fit2[pcitems2], predict, tempdata, type="probs")
                    #                        infotemp = odds

                    #                        ## Funktion kann nicht benutzt werden, da sie auf nicht manipulierte pcitems zugreift
                    #                        infotemp[pcitems2] = lapply(odds[pcitems2], FUN.infoMC.IND)
                    #                        infotemp[-pcitems2] = lapply(odds[-pcitems2], FUN.info)
                    #                        infotemp = simplify2array(infotemp)
                    #                    }
                    infotemp = FUN.EntroMC(pcitems2,tempdata, fit2)
                resttemp2[j] = sum(infotemp)
            } else {
                resttemp2[j] = 0 
            }
        }

        <<fit>>
            odds = fit

        #            ## calculation of current rest entropie
        #            if (length(pcitems) == 1) {
        #                odds = lapply(fit, predict, test[k,], type="response")
        #                infotemp = odds
        #                infotemp = lapply(odds, FUN.info)
        #                infotemp = simplify2array(infotemp)
        #            } else {
        #                pcitems = pcitems[2:length(pcitems)]
        #                odds[-pcitems] = lapply(fit[-pcitems], predict, test[k,], type="response")
        #                odds[pcitems] = lapply(fit[pcitems], predict, test[k,], type="probs")
        #                infotemp = odds

        #                ## Funktion kann nicht benutzt werden, da sie auf nicht manipulierte pcitems zugreift
        #                infotemp[pcitems] = lapply(odds[pcitems], FUN.infoMC.IND)
        #                infotemp[-pcitems] = lapply(odds[-pcitems], FUN.info)
        #                infotemp = simplify2array(infotemp)
        #            }
        infotemp = FUN.EntroMC(pcitems,test[k,], fit)
        resttemp[i-1] = sum(infotemp)
        query = c(query, which(names(test[-query][which(resttemp2 == min(resttemp2))[1]]) == names(test))[1])
        ## stimmt das? sollte das nicht mit resttemp2 arbeiten?
        ##        modell[[i]] = fit[[which(infotemp == max(infotemp))]]
        modell[[i]] = fit[[which(resttemp2 == min(resttemp2))[1]]]
    }

    ## calculation of last rest entropie
    if (length(test) == items) {
        resttemp[items] = 0
    } else {
        fit = NULL
        pcitems = 0
        pcitems = c(0,which(names(test[-query]) %in% names(test[pcitemsalt])))
        for (j in 1:length(test[-query])) {
            if (j %in% pcitems) {
                fit[[j]] = polr(reformulate(names(test[query]), names(test[-query][j])), data = test)
            } else {
                fit[[j]] = glm(reformulate(names(test[query]), names(test[-query][j])), data = test, family = "binomial"(link=logit))
            }
        }

        <<fit>>
            #                if (length(pcitems) == 1) {
            #                    odds = lapply(fit, predict, test[k,], type="response")
            #                    infotemp = odds
            #                    infotemp = lapply(odds, FUN.info)
            #                    infotemp = simplify2array(infotemp) 
            #                } else {
            #                    pcitems = pcitems[2:length(pcitems)]
            #                    odds[-pcitems] = lapply(fit[-pcitems], predict, test[k,], type="response")
            #                    odds[pcitems] = lapply(fit[pcitems], predict, test[k,], type="probs")
            #                    infotemp = odds

            #                    ## Funktion kann nicht benutzt werden, da sie auf nicht manipulierte pcitems zugreift
            #                    infotemp[pcitems] = lapply(odds[pcitems], FUN.infoMC.IND)
            #                    infotemp[-pcitems] = lapply(odds[-pcitems], FUN.info)
            #                    infotemp = simplify2array(infotemp)
            #                }
            infotemp = FUN.EntroMC(pcitems,test[k,], fit)
        resttemp[items] = sum(infotemp)
    }

    ## calculation of choosen modell
    pcitems = 0
    pcitems = c(pcitems,which(query %in% pcitemsalt))
    #        if (length(pcitems) == 1) {
    #            odds = modell
    #            odds = lapply(modell, predict, test[k,], type="response")
    #            infotemp = odds
    #            infotemp = lapply(odds, FUN.info)
    #            infotemp = simplify2array(infotemp)
    #        } else {
    #            pcitems = pcitems[2:length(pcitems)]
    #            odds = modell
    #            odds[-pcitems] = lapply(modell[-pcitems], predict, test[k,], type="response")
    #            odds[pcitems] = lapply(modell[pcitems], predict, test[k,], type="probs")
    #            infotemp = odds

    #            ## Funktion kann nicht benutzt werden, da sie auf nicht manipulierte pcitems zugreift
    #            infotemp[pcitems] = lapply(odds[pcitems], FUN.infoMC.IND)
    #            infotemp[-pcitems] = lapply(odds[-pcitems], FUN.info)
    #            infotemp = simplify2array(infotemp)
    #        }
    infotemp = FUN.EntroMC(pcitems,test[k,], modell)
    return(c(infotemp, resttemp))
})

resttemp = (infoall[(items+1):(items*2),])
infoall = infoall[1:items,]

SumSDtemp = sd(infoall[1,])
for (i in 2:length(infoall[,1])) {
    SumSDtemp[i] = sd(colSums(infoall[1:i,]))
}

SumSD$indivbedsortpred = c(0,SumSDtemp)
EEE$indivbedsortpred = c(0,rowMeans(infoall))
Restinfo$indivbedsortpred = c(0,rowMeans(resttemp))
RestinfoSD$indivbedsortpred = c(0,apply(resttemp, 1, sd))

pcitems = pcitemsalt
EEE
SumSD
Restinfo
RestinfoSD
#+END_SRC

*** Experimenteller Code
#+BEGIN_SRC R :exports code :results output :noweb yes
calculationtime <- proc.time()

## initializing
fit = NULL
infoall = NULL
odds = NULL
resttemp = NULL
query = NULL
modell = NULL
resttemp = NULL
pcitems = pcitemsalt

## first item
for (i in 1:length(test)) {
    if (i %in% pcitems) {
        fit[[i]] = polr(reformulate('1', names(test[i])), data = test)
    } else {
        fit[[i]] = glm(reformulate('1', names(test[i])), data = test, family = "binomial"(link=logit))
    }
}

odds = fit
odds[-pcitems] = lapply(fit[-pcitems], predict, test[1,], type="response")
odds[pcitems] = lapply(fit[pcitems], predict, test[1,], type="probs")
infotemp = FUN.infotemp.IND(odds)
query = which(names(test[which(infotemp == max(infotemp))[1]]) == names(test))[1]

modell[[1]] = fit[[query]]
queryinit = query
fit = NULL
Restentropie2 = NULL
infoall = matrix(nrow=persons,ncol=items)
## multicore calculation
#    infoall = simplify2array(foreach(k=1:persons) %dopar% {
for (k in 1:persons) {
    query = queryinit
    Restentropie = NULL
    resttemp2 = NULL
    resttemp = NULL
    calcu = 0
    calcutime = proc.time()
    antwortmuster = vector(length=(length(test)+2))
    if (file.exists('database.dat')) {
        database = read.table('database.dat')
    }
    antwortmuster[1] = query[1] + as.numeric(as.character(test[k,query[1]]))/100
    #                antwortmuster[2] = test[k,query[1]]
    for (i in 2:items) {
        odds = NULL
        infotemp = NULL
        fit = NULL
        fit2 = NULL
        fitplus = NULL
        fitminus = NULL
        infotemp2 = NULL
        found = 0
        pcitems = c(0,which(names(test[-query]) %in% names(test[pcitemsalt])))
        Liste = NULL
        foundit = 0
        ## prediction for all not-answerd questions
        if (exists("database")) {
            for (m in 1:length(database[,1])) {
                for (u in 1:length(query)) {
                    if (sort(antwortmuster[1:length(query)])[u] != database[m,u]) {
                        break
                    }
                    if (database[m,(length(query)+3)] == 0 && u == length(query)) {
                        found = database[m,(length(query)+2)]
                        resttemp[i-1] = database[m,(length(query)+1)]
                        query = c(query, found)
                    }
                }
                if (found != 0) {
                    break
                }
            }
        }
        if (found == 0) {
            calcu = calcu+1
            isgood = NULL
            for (q in 1:length(test[-query])) {
                if (q %in% pcitems) {
                    fit[[q]] = polr(reformulate(names(test[query]), names(test[-query][q])), data = test)
                } else {
                    fit[[q]] = glm(reformulate(names(test[query]), names(test[-query][q])), data = test, family = "binomial"(link=logit))
                }
            }
            infotemp = FUN.EntroMC(pcitems,test[k,], fit)
            isgood = infotemp == max(infotemp)[1]
            Liste =foreach(j=1:length(test[-query])) %dopar% {
                chance = NULL
                if (j %in% pcitems) {
                    #    fit = polr(reformulate(names(test[query]), names(test[-query][j])), data = test)
                    chance = predict(fit[[j]], test[k,], type="probs")
                } else {
                    #                                                    fit = glm(reformulate(names(test[query]), names(test[-query][j])), data = test, family = "binomial"(link=logit))
                    chance = predict(fit[[j]], test[k,], type="response")
                    chance[2] = 1-chance[1]
                }
                #                                             infotemp = FUN.EntroMC(pcitems,test[k,], fit)
                #      tempdata = test[k,]
                #          if (j %in% pcitems) {
                #              for (s in 1:length(chance)) {
                #                  tempdata[-query][j] = factor(s-1) #dies muss noch bearbeitet werden (chancen...)
                #                  infotemp = FUN.EntroMC(pcitems,tempdata, fit)*chance[s]
                #                  resttemp2[s] = sum(infotemp)
                #              }
                #              resttemp2 = sum(resttemp2)
                #          } else {
                #              tempdata[-query][j] = 1
                #              infotemp = FUN.EntroMC(pcitems2,tempdata, fit2)*chance[1]
                #              resttemp2 = sum(infotemp)
                #              tempdata[-query][j] = 0
                #              infotemp = FUN.EntroMC(pcitems2,tempdata, fit2)*chance[2]
                #              resttemp2[2] = sum(infotemp)
                #              resttemp2 = sum(resttemp2)
                #          }
                #          fit2=NULL

                resttemp2 = NULL
                ## prediction for all not-answered questions after prediction
                if (length(test[-query]) > 1 && isgood[j]) {
                    pcitems2 = c(0,which(names(test[-query][-j]) %in% names(test[pcitemsalt])))
                    for (n in 1:length(test[-query][-j])) {
                        if (n %in% pcitems2) {
                            fit2[[n]] = polr(reformulate(names(c(test[query], test[-query][j])), names(test[-query][-j][n])), data = test)
                        } else {
                            fit2[[n]] = glm(reformulate(names(c(test[query], test[-query][j])), names(test[-query][-j][n])), data = test, family = "binomial"(link=logit))
                        }
                    }

                    ## calculation of rest entropie for each possibility
                    tempdata = test[k,]
                    if (j %in% pcitems) {
                        #            for (s in 1:length(chance)) {
                        #                tempdata[-query][j] = factor(s-1) #dies muss noch bearbeitet werden (chancen...)
                        #                infotemp = FUN.EntroMC(pcitems2,tempdata, fit2)*chance[s]
                        #                resttemp2[s] = sum(infotemp)
                        #                                                            }
                        #            resttemp2 = sum(resttemp2)
                        infotemp = FUN.EntroMC(pcitems2,tempdata, fit2)
                        resttemp2 = sum(infotemp)

                    } else {
                        tempdata[-query][j] = 1
                        infotemp = FUN.EntroMC(pcitems2,tempdata, fit2)*chance[1]
                        resttemp2 = sum(infotemp)
                        tempdata[-query][j] = 0
                        infotemp = FUN.EntroMC(pcitems2,tempdata, fit2)*chance[2]
                        resttemp2[2] = sum(infotemp)
                        resttemp2 = sum(resttemp2)
                    }
                    fit2=NULL
                } else {
                    if (isgood[j]) {
                        resttemp2 = 0
                    } else {
                        resttemp2 = 55555555
                    }
                }
                return(resttemp2)
            }
            #                                             Liste = unlist(Liste, recursive = FALSE)

            #                                             resttemp2 = unlist(Liste[(1:(length(Liste)/2))*2])
            #                                             fit = Liste[(1:(length(Liste)/2))*2-1]
            resttemp2 = simplify2array(Liste)
            query = c(query, which(names(test[-query][which(resttemp2 == min(resttemp2))[1]]) == names(test))[1])
            modell[[i]] = fit[[which(resttemp2 == min(resttemp2))[1]]]
            <<fit>>
                odds = fit

            infotemp = FUN.EntroMC(pcitems,test[k,], fit)
            resttemp[i-1] = sum(infotemp)

        }
        antwortmuster[i] = query[i] + as.numeric(as.character(test[k,query[i]]))/100

        if (found == 0) {
            temp = antwortmuster
            temp[1:(i-1)] = sort(antwortmuster[1:(i-1)])
            temp[i] = resttemp[i-1]
            temp[i+1] = query[i]
            write(temp, file='database.dat', append=TRUE, ncolumns=length(antwortmuster))
        }
        plot(resttemp, type='l', col=rgb(0,0.7,0.7))
    }
    ## calculation of last rest entropie
    if (length(test) == items) {
        resttemp[items] = 0
    } else {
        fit = NULL
        pcitems = 0
        pcitems = c(0,which(names(test[-query]) %in% names(test[pcitemsalt])))
        for (j in 1:length(test[-query])) {
            if (j %in% pcitems) {
                fit[[j]] = polr(reformulate(names(test[query]), names(test[-query][j])), data = test)
            } else {
                fit[[j]] = glm(reformulate(names(test[query]), names(test[-query][j])), data = test, family = "binomial"(link=logit))
            }
        }

        <<fit>>

            infotemp = FUN.EntroMC(pcitems,test[k,], fit)
        resttemp[items] = sum(infotemp)
    }

    ## calculation of choosen modell
    pcitems = 0
    pcitems = c(pcitems,which(query %in% pcitemsalt))
    if (calcu != 0) {
        temp = vector(length=(length(test)+2))
        temp[2] = k
        temp[3] = (proc.time() - calcutime)[3]
        temp[4] = calcu
        write(temp, file='database.dat', append=TRUE, ncolumns=length(antwortmuster))
    }
    #infotemp = FUN.EntroMC(pcitems,test[k,], modell)
    #    return(c(infotemp, resttemp))
    infoall[k,] = resttemp
}#})

#restt = (infoall[(items+1):(items*2),])
#infoall = infoall[1:items,]

#    SumSDtemp = sd(infoall[1,])
#   for (i in 2:length(infoall[,1])) {
#      SumSDtemp[i] = sd(colSums(infoall[1:i,]))
# }

#SumSD$indivbedsortpred = c(0,SumSDtemp)
#EEE$indivbedsortpred = c(0,rowMeans(infoall))
Restinfo$indivbedsortpred = c(0,colMeans(infoall))
RestinfoSD$indivbedsortpred = c(0,apply(infoall, 2, sd))

pcitems = pcitemsalt
#EEE
#SumSD
Restinfo
RestinfoSD
#+END_SRC

#+RESULTS:
#+begin_example
   indivbedsortpred  indivbedsort
1        0.00000000  5.512415e+01
2       51.35907667  5.135908e+01
3       48.81582000  4.881582e+01
4       46.75794333  4.562663e+01
5       45.51642000  4.325132e+01
6       43.51850333  4.112426e+01
7       42.37757333  4.042258e+01
8       40.79356000  3.854947e+01
9       39.57111000  3.716378e+01
10      38.85900000  3.618153e+01
11      38.49110333  3.519636e+01
12      37.39650667  3.388109e+01
13      36.53168000  3.279737e+01
14      35.12376000  3.180080e+01
15      34.01320667  3.026254e+01
16      33.22901667  2.864349e+01
17      32.61010000  2.724371e+01
18      31.95430667  2.623535e+01
19      31.09503667  2.508785e+01
20      29.53204333  2.405066e+01
21      28.77588667  2.277454e+01
22      27.71298667  2.177713e+01
23      26.92562000  2.034057e+01
24      26.31079000  1.946257e+01
25      25.54026333  1.803385e+01
26      24.33001333  1.721388e+01
27      22.75637333  1.597181e+01
28      21.28342667  1.498193e+01
29      20.29931333  1.396405e+01
30      19.24166667  1.307385e+01
31      18.20082333  1.191703e+01
32      17.75165667  1.097635e+01
33      16.88355000  1.016586e+01
34      15.95108333  9.202684e+00
35      15.69948333  7.899795e+00
36      14.97986333  7.097354e+00
37      14.29918667  6.081928e+00
38      13.74156000  5.460851e+00
39      12.78344000  4.772650e+00
40      11.90049333  4.067948e+00
41      11.14289667  3.413253e+00
42      10.60420000  2.846556e+00
43       9.76043400  2.350530e+00
44       8.00142567  1.769718e+00
45       7.27654133  1.480445e+00
46       7.18327067  1.097974e+00
47       6.65206400  7.927647e-01
48       5.28410967  5.259278e-01
49       4.85331833  3.187139e-01
50       3.26410533  1.914815e-01
51       2.61981200  6.822902e-02
52       1.88945100  1.518414e-02
53       0.63633380  3.023751e-03
54       0.01750709 -5.770756e-06
55       0.00000000  0.000000e+00
   indivbedsortpred indivbedsort
1        0.00000000 0.000000e+00
2        0.73626593 7.362653e-01
3        0.31769969 3.176987e-01
4        0.58883257 4.793886e-01
5        0.47281875 5.785675e-01
6        1.03360931 6.393388e-01
7        1.35424266 9.577214e-01
8        1.21930633 1.274269e+00
9        1.32488984 2.027016e+00
10       1.30099273 1.909940e+00
11       0.80615468 1.643141e+00
12       0.95669944 1.960404e+00
13       0.90708640 1.964451e+00
14       0.62132121 1.529076e+00
15       1.18971368 1.878734e+00
16       0.44513378 2.053826e+00
17       0.45204319 2.220281e+00
18       0.36223211 2.052133e+00
19       0.33878530 1.876594e+00
20       0.32835853 2.009701e+00
21       0.56435673 1.974349e+00
22       0.83285755 1.933595e+00
23       0.34692387 2.002850e+00
24       0.35767683 1.692322e+00
25       0.50423868 1.799258e+00
26       0.54804700 1.725785e+00
27       0.45201665 1.812078e+00
28       1.05109429 1.929145e+00
29       0.96785497 1.743920e+00
30       1.13072874 1.755639e+00
31       1.21593032 1.502964e+00
32       1.81961329 1.570259e+00
33       1.79432292 1.452640e+00
34       1.49351920 1.378060e+00
35       1.41433285 1.133211e+00
36       0.79995535 1.130159e+00
37       0.52543705 9.339317e-01
38       0.14859745 7.751506e-01
39       0.11536975 9.749697e-01
40       0.28325276 8.970542e-01
41       0.40936682 8.093955e-01
42       0.34851890 6.485482e-01
43       0.19618676 6.307331e-01
44       0.44100079 5.379630e-01
45       0.10431056 6.920624e-01
46       0.36854398 5.264797e-01
47       0.37862328 3.919423e-01
48       0.46464706 2.473037e-01
49       0.68695282 2.055540e-01
50       0.50191052 1.517166e-01
51       0.61925114 3.453077e-02
52       0.88309830 7.483717e-03
53       0.32651072 4.935855e-03
54       0.01060055 7.496422e-06
55       0.00000000 0.000000e+00
#+end_example

*** Schlussberechnungen
Hier werden lediglich ein paar Aufräumarbeiten in den Daten noch erledigt, um diese dann gut zeichnen zu können.
#+NAME: statisticend
#+BEGIN_SRC R :exports code :results output :noweb yes
if (names(EEE[1]) == 'kill') {
    EEE = EEE[-1]
}

if (names(SumSD[1]) == 'kill') {
    SumSD = SumSD[-1]
}

if (names(Restinfo[1]) == 'kill') {
    Restinfo = Restinfo[-1]
    RestinfoSD = RestinfoSD[-1]
}

for (i in 1:length(EEE[1,])) {
    for (j in 1:length(EEE[,1])) {
        summe[j,i] = sum(EEE[1:j,i])
    }
}

fit = NULL
pcitems = pcitemsalt
for (i in 1:length(test)) {
    if (i %in% pcitems) {
        fit[[i]] = polr(reformulate('1', names(test[i])), data = test)
    } else {
        fit[[i]] = glm(reformulate('1', names(test[i])), data = test, family = "binomial"(link=logit))
    }
}

odds = fit
odds[-pcitems] = lapply(fit[-pcitems], predict, test[1,], type="response")
odds[pcitems] = lapply(fit[pcitems], predict, test[1,], type="probs")
infotemp = FUN.infotemp.IND(odds)
Restinfo[1,] = sum(infotemp)

names(summe) = names(EEE)

if (exists("benchmark")) {
    benchmark = array(c(benchmark,(proc.time() - calculationtime)[3]))
} else {
    benchmark = (proc.time() - calculationtime)[3]
}
#+END_SRC

*** Formel für die Modellanpassung
Hier kann noch bestimmt werden, ob die binärlogistischen Regressionen noch schlechte Items verwerfen, oder einfach mit allen rechnen.
Änderungen, die hier gemacht werden, werden automatisch im gesamten Code angepasst, da dieser Teil mit noweb-syntax eingebunden ist.

Aus statistischer Sicht ist es natürlich viel besser, wenn schlechte Items noch verworfen und noch Interaktionen hinzugefügt werden.
Was hier aber dagegen spricht, ist die dadurch resultierende Berechnungsdauer.
So sind selbst die einfacheren obigen Modell auch nach Stunden nicht fertig.
#+NAME: fit
#+BEGIN_SRC R :exports code
#fit = mclapply(fit, step, trace = 0)
#fit = mclapply(fit, step, ~.^2, trace = 0)
#+END_SRC

*** Benchmark
#+BEGIN_SRC R :noweb yes :results output graphics :file /images/benchmark.png :exports code
plot(benchmark, type="l", col=rgb(0,0,0), ann=F)
title(xlab="Durchlauf")
title(ylab="Dauer")
#+END_SRC

#+RESULTS:
[[file:/images/benchmark.png]]

*** infografik
Hier ist noch ein letztes kleines Bisschen an Code, welches die derzeit kalkulierten Ergebnisse in eine Grafik packt.
Zudem werden eine Legende generiert und die Berechnungsdauer angegeben.
#+NAME: grafik
#+BEGIN_SRC R :noweb yes :results output graphics :file /images/entropie2.png :exports code
farbe = NULL
farbeSD = NULL
for (j in 1:(length(summe[1,]))) {
    r = runif(1,0.1,0.9)
    g = runif(1,0.1,0.9)
    b = runif(1,0.1,0.9)
    farbe[j] = rgb(r^1.2, g^1.2, b^1.2)
    farbeSD[j] = rgb(sqrt(r), sqrt(g), sqrt(b))
}

plot(0:(length(test)), type="l", col=rgb(0,0,0), ann=F)
for (i in 1:(length(summe[1,]))) {
    lines(summe[,i], col=farbe[i])
    if (dim(SumSD[names(SumSD) == names(summe[i])])[2] != 0) {
        lines(summe[,i]+SumSD[names(summe[i])],lty = 4, col=farbeSD[i])
        lines(summe[,i]-SumSD[names(summe[i])],lty = 4, col=farbeSD[i])
    }
    if (dim(Restinfo[names(Restinfo) == names(summe[i])])[2] != 0) {
        lines(Restinfo[names(summe[i])], col=farbe[i])
        lines(Restinfo[names(summe[i])]+RestinfoSD[names(summe[i])],lty = 4, col=farbeSD[i])
        lines(Restinfo[names(summe[i])]-RestinfoSD[names(summe[i])],lty = 4, col=farbeSD[i])
    }
}

title(xlab="Anzahl der beantworteten Fragen")
title(ylab="Entropie in bit")
legend(length(test)/4, length(test), c(names(summe), round(benchmark[length(benchmark)])), cex=0.9, col=c(farbe, rgb(1,1,1)), lty=1)
#+END_SRC

#+RESULTS: grafik
[[file:/images/entropie2.png]]
