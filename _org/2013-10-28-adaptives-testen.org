#+BEGIN_COMMENT
---
layout: post
title: Adaptives Testen
father: Wissenschaft
---
#+END_COMMENT
* Adaptives Testen
Beim adaptiven Testen werden die Möglichkeiten einer computerbasierten Testung in erweitertem Maße ausgenutzt.
Es wird innerhalb der Testung auf Grund der bereits beantworteten Fragen auf den Fähigkeitsgrad des Probanden geschätzt,
um ihm als nächstes eine Frage zu geben, die diesen reflektiert.

#+BEGIN_SRC ditaa :file /images/adaptiveditaa.png :exports code

+---------+   +-----------------+   +---------------+
| Item    |-->| Modellschätzung |-->|   Schätzung   |
| Antwort |   +-----------------+   | nächstes Item |
+---------+                         +---------------+
    ^                                       |
    |                                       |
    +---------------------------------------+

#+END_SRC 

** Kriterien
Wie genau die Frage ausgewählt wird hängt vornehmlich von den Zielen der Testung und den Nebenwirkungen, die man ggf. 
vermeiden möchte, ab. So wäre eine Frage, die der Proband mit einer Chance von 50% lösen kann ideal im Sinne eines 
Informationsgewinnes über den Probanden, da die Entropie maximal ist. 

Entropie stellt nicht nur Chaos, sondern auch Informationsdichte nach Shannon dar 
(vgl. [[http://de.wikipedia.org/wiki/Entropie_%28Informationstheorie%29][Wikipedia]]).
Die folgende Formel ergiebt die Entropie eines Ereignisses. Hierbei ist $n$ die Anzahl der Möglichkeiten und $p_i$ 
die jeweiligen Wahrscheinlichkeiten dieser (sich ausschließender) Möglichkeiten.

$$ H = - \sum_{i=1}^n p_i \cdot \log_2{p_i} $$

Betrachten wir ein binäres System, also nur Fragen die entweder vollständig falsch oder vollständig richtig beantwortet
werden können, so haben wir $n = 2$ und $p_2 = 1 - p_1$.

$$ H_2 = - p \cdot \log_2{p} - (1 - p) \cdot \log_2(1 - p) $$

Hieraus ergiebt sich, dass der Informationsgewinn bei $p = .5$ (im binären) maximal ist, da die Funktion symmetrisch ist und bei
$p = 0$ auf beiden Seiten $0$ ergibt.

$$ H_{max} = - 0.5 \cdot \log_2{0.5} - 0.5 \cdot \log_2{0.5} = 1 \mathrm{bit} $$

Hierbei ist $bit$ die übliche Einheit des Informationsgehaltes, auf Grund des $\log_2$. Es kann also ein Informationsgehalt
von 8 bit mit Hilfe eines bytes dargestellt werden, sprich mit 8 Nullen oder Einsen (z.B. 10101010).

#+BEGIN_SRC R :results output graphics :file /images/entropie.png :exports results
x = (0:100)/100
y = -x*log(x,2)-(1-x)*log(1-x,2)
plot(x,y,type="l",xlab=expression(Lösungswahrscheinlichkeit),ylab=expression("Entropie in bit"),  main="Entropieverteilung")
#+END_SRC

#+RESULTS:
[[file:/images/entropie.png]]

Mit der Formel für tatsächliche und für maximale Entropie kann die Redundanz ausgerechnet werden, welche in einer 
Testkonstruktion als Indikator für das Potential der Verbesserung durch ein adaptives Testverfahren benutzt werden kann.

$$ R = H_{max} - H $$

Somit kann im binären ein Test im idealfall um $R$ Fragen verkleinert werden, ohne an Informationen einzubüßen. 
Befinden sich im Test auch Fragen, die nicht binär sind, so verändert sich die Situation ein wenig.
Die Entropie wird stets maximal bei gleichen Wahrscheinlichkeiten. Gibt es nun bei einer Frage z.B. 0, 1, 2 oder 3 Punkte
gibt es eine maximale Entropie von $H_{max} = - \log_2{0.25} = 2 \mathrm{bit}$. Somit kann man einen Test auch um $R/2$ solcher
Fragen ohne Informationsverlust verkleinern.

*** Informationsgehalt in KoMus
Im August diesen Jahres habe ich mit Teilen des KoMus-Testes für musikalische Kompetenz eine empirische Studie
durchgeführt. Der KoMus-Test liegt in einem nicht adaptiven Format vor.

Interessant ist nun, die Überlegung, wieviel der Test von einer Überführung in einen adaptiven Test profitieren würde.

**** Durchschnittlicher Schüler
Der Simplizität halber können wir annehmen, dass ein Schüler genau die durchschnittlichen Lösungswahrscheinlichkeiten
für ein Item aufweist.

So muss man nur die Entropie mit den klassischen Itemschwierigkeiten der Items berechnen:

$$ H = \sum_{i=1}^n(- P_i \cdot \log_2{P_i} - (1 - P_i) \cdot \log_2(1 - P_i)) $$

Hierbei ist $P_i$ die klassische Itemschwierigkeit des Items $i$ und $n$ die Anzahl der Items. Ferner nimmt diese Formel
nur dichotome Items an.

**** Vierdimensional
Die Entropie ist jedoch eigentlich noch niedriger, wenn man die Schwierigkeiten adaptiv berechnet. Es handelt sich aber
immernoch um einen nicht adaptiven Test mit fester Reihenfolge. Es wird nur eine spezialform der Entropie, die bedingte
Entropie, benutzt (vgl. [[http://de.wikipedia.org/wiki/Bedingte_Entropie][Wikipedia]]).

Um die bedingte Lösungschance und somit auch die bedingte Entropie zu berechnen, werden alle Items der selben Dimension
einer logistisch binären Regression verwendet um die individuell Itemschwierigkeit eines Items der gleichen Dimension zu
berechnen.

$$ H = \sum_{D=1}^4(\sum_{i=1}^{n(D)}(- R \cdot \log_2{R}) - (1 - R) \cdot \log_2(1- R))$$
$$ R = Reg_2(P_{ivD}|\sum_{m=1}^{i(D)-1}P_{vmD}) $$

Hierbei ist $Reg_2(a|b)$ die binärlogistische Regression mit der AV $a$ und den UV $b$.

**** n-Dimensional
Das obige Modell nimmt jedoch an, dass die einzelnen Dimensionen nicht korrelieren und somit Itemantworten einer Dimension 
keine Information (also Entropiesenkung) über andere Dimensionen zulassen.

Dies ist aber eine nicht notwendige Einschränkung, die die Berechnung nicht nur weniger effektiv, sondern auch
komplizierter macht.

Berücksichtigen wir unabhängig von der Dimensionszugehörigkeit einfach alle bereits beantworteten Items, die einen
signifikanten Einfluss auf die Frage haben, haben wir im Endeffekt ein n-dimensionales Modell, wobei $n$ die Anzahl der
Fragen ist.

$$ H = \sum_{i=1}^n(- R \cdot \log_2{R} - (1 - R) \cdot \log_2(1 - R)) $$
$$ R = Reg_2(P_{iv}|\sum_{m=1}^{i-1}P_{vm}) $$

***** Probleme
Mögliche Probleme dieser Methode sind fehlende Datensätze, da die binärlogistische Regression normalerweise alle Fälle
ausschließt, die auch nur bei einem der UV keinen Wert hat. Durch den maßgeschneiderten Testweg ist es bei einem 
Itempool, der nicht komplett erschöpft wird, unmöglich diese Regression so durchzuführen. Dementsprechend müssen
andere Methoden gewählt werden, um mit fehlenden Daten umzugehen.

Eine Möglichkeit wäre, nicht vorhandene Antworten in den Datensätzen zu simulieren. Diese Simulation würde von den Items
die am sichersten geschätzt werden können zu den Items, die schwer geschätzt werden können stattfinden.

Der Grund hierfür liegt daran, dass bei einer sehr sicheren Schätzung der Entropiegehalt sich nur wenig ändert, 
aber es gleich viel mehr Personen gibt, die seriös für schwerere Schätzungen verwendet werden können, was diese
Schätzungen erleichtert.

Die Simulation sollte nach jeder Testung durchgeführt werden, um die Simulation mehr und mehr zu verbessern. Das dieses
Verfahren direkt einen Nutzen erbringt, sollte daran sichtbar sein, dass die Lösungen der alten Datensätze immer besser
retrospektiv vorhergesagt werden können und somit davon außgegangen werden kann, dass auch bei aktuellen Testungen
die Schätzungen besser sind und somit effektiver gemessen werden kann.

* Nicht adaptives Testen
 
* Adaptives Testen

** Umsetzung
   
*** Programmierung
   
**** Initialisierung
#+NAME: statistic
#+BEGIN_SRC R :session stat :exports both :results output :noweb yes
require(MASS)
library(multicore)
library(foreach)
library(doMC)
registerDoMC(3)

calculationtime <- proc.time()
komus = read.table("data/data_komus_bin2.dat",header=TRUE) 
komusmult = data.frame(read.table("data/komus.csv",header=TRUE, sep=','))
multifragen = array(which(sapply(komusmult, max) > 1))
multifragenalt = multifragen
komusmult[multifragen] = lapply(komusmult[multifragen],factor)

FUN.EntropieMC = function(x) {return(rowSums(-x*log(x+0.00000001, 2)))}
FUN.EntropieMC.IND = function(x) {return(sum(-x*log(x+0.00000001, 2)))}
FUN.Entropie = function(x) {return(-x*log(x+0.000001, 2)-(1-x)*log(1-x+0.00001, 2))}
FUN.Chances = function(x) {
    if (length(multifragen) > 0) {
        x[-multifragen] = lapply(x[-multifragen], predict, type="response")
        x[multifragen] = lapply(x[multifragen], predict, type="probs")
    } else {
        x = lapply(x, predict, type="response")
    }
    return(x)
}
FUN.Chances.IND = function(x,y) {
    x[-multifragen] = lapply(x[-multifragen], predict, data = komusmult[y,], type="response")
    x[multifragen] = lapply(x[multifragen], predict, data = komusmult[y,], type="probs")
    return(x)
}
FUN.Entropietemp = function(x) {
    if (length(multifragen) > 0) {
        x[multifragen] = lapply(x[multifragen], FUN.EntropieMC)
        x[-multifragen] =lapply(x[-multifragen], FUN.Entropie)
    } else {
        x =lapply(x, FUN.Entropie)
    }
    x = simplify2array(x)
    return(x)
}
FUN.Entropietemp.IND = function(x) {
    if (length(multifragen) > 0) {
        x[multifragen] = lapply(x[multifragen], FUN.EntropieMC.IND)
        x[-multifragen] =lapply(x[-multifragen], FUN.Entropie)
    } else {
        x =lapply(x, FUN.Entropie)
    }
    x = simplify2array(x)
    return(x)
}



FUN.EntroMC = function(funmultifragen, fundata, funmod) {

            if (length(funmultifragen) == 1) {
                chances = lapply(funmod, predict, fundata, type="response")
                Entropietemp = chances
                Entropietemp = lapply(chances, FUN.Entropie)
                Entropietemp = simplify2array(Entropietemp)
            } else {
                funmultifragen = funmultifragen[2:length(funmultifragen)]
                chances = funmod
                chances[-funmultifragen] = lapply(funmod[-funmultifragen], predict, fundata, type="response")
                chances[funmultifragen] = lapply(funmod[funmultifragen], predict, fundata, type="probs")
                Entropietemp = chances
                
                Entropietemp[funmultifragen] = lapply(chances[funmultifragen], FUN.EntropieMC.IND)
                Entropietemp[-funmultifragen] = lapply(chances[-funmultifragen], FUN.Entropie)
                Entropietemp = simplify2array(Entropietemp)
            }
return(Entropietemp)
}






Entropie = NULL
chances = NULL
fitting = NULL
modell = NULL
summe = data.frame()
############
items = length(komusmult)
#persons = length(komusmult[,1])
#items = 50
persons = 2
############

EEE = data.frame(matrix(ncol = 1, nrow = items+1))
SumSD = data.frame(matrix(ncol = 1, nrow = items+1))
RestEntropie = data.frame(matrix(ncol = 1, nrow = items+1))
RestEntropieSD = data.frame(matrix(ncol = 1, nrow = items+1))
names(EEE) = 'kill'
names(SumSD) = 'kill'
names(RestEntropie) = 'kill'
names(RestEntropieSD) = 'kill'
#+END_SRC

#+RESULTS: statistic
#+begin_example
Lade nötiges Paket: MASS
foreach: simple, scalable parallel programming from Revolution Analytics
Use Revolution R for scalability, fault tolerance and more.
http://www.revolutionanalytics.com
Lade nötiges Paket: iterators
Lade nötiges Paket: parallel

Attache Paket: ‘parallel’

The following object(s) are masked from ‘package:multicore’:

    mclapply, mcparallel, pvec
#+end_example

**** Unbedingte und bedingte Entropie in normaler Reihenfolge
#+NAME: statistic1
#+BEGIN_SRC R :session stat :exports both :results output :noweb yes
    modell = NULL
    
    multifragen = multifragen[multifragen <= items]
    if (1 %in% multifragen) {
        modell[[1]] = polr(reformulate('1', names(komusmult[1])), data = komusmult)
    } else {
        modell[[1]] = glm(reformulate('1', names(komusmult[1])), data = komusmult, family = "binomial"(link=logit))
    }
    
    for (i in 2:items) {
        if (i %in% multifragen) {
            modell[[i]] = polr(reformulate(names(komusmult[1:i-1]), names(komusmult[i])), data = komusmult)
        } else {
            modell[[i]] = glm(reformulate(names(komusmult[1:i-1]), names(komusmult[i])), data = komusmult, family = "binomial"(link=logit))
        }
    }
    
    fitting = modell
    <<fitting>>
    chances = FUN.Chances(fitting)
    
    Entropietemp = FUN.Entropietemp(chances)
    
    ### Without relations ###
    fitting = lapply(fitting, update, ~ 1)
    chances2 = FUN.Chances(fitting)
    
    Entropietemp2 = FUN.Entropietemp(chances2)
    
    multifragen = multifragenalt
    
    SumSDtemp = sd(Entropietemp[,1])
    for (i in 2:length(Entropietemp[1,])) {
        SumSDtemp[i] = sd(rowSums(Entropietemp[,1:i]))
    }
    
    SumSD$bedunsort = c(0,SumSDtemp)
    
    EEE$bedunsort = c(0,colMeans(Entropietemp))
    EEE$unbedunsort = c(0,colMeans(Entropietemp2))
    EEE$unbedsort = c(0,sort(colMeans(Entropietemp2), decreasing =TRUE))
    Entropietemp2 = data.frame(Entropietemp2)
    names(Entropietemp2) = names(komusmult[1:length(Entropietemp2)])    
#+END_SRC

#+RESULTS: statistic1
:  Warnmeldung:
: glm.fit: Angepasste Wahrscheinlichkeiten mit numerischem Wert 0 oder 1 aufgetreten

**** Bedingte, sortierte Entropie
#+NAME: statistic2
#+BEGIN_SRC R :session stat :exports both :results output :noweb yes
    modell = NULL
    chances = NULL
    fitting = NULL
    
    ############## sortierte Reihenfolge
    for (i in 1:items) {
        if (i %in% multifragen) {
            modell[[i]] = polr(reformulate('1', names(komusmult[i])), data = komusmult)
        } else {
            modell[[i]] = glm(reformulate('1', names(komusmult[i])), data = komusmult, family = "binomial"(link=logit))
        }
    }
    
    chances = FUN.Chances(modell)
    Entropietemp = FUN.Entropietemp(chances)
    Entropietemp = data.frame(Entropietemp)
    names(Entropietemp) = names(komusmult[1:length(Entropietemp)])
    komus2 = komusmult[c(names(sort(colMeans(Entropietemp), decreasing=TRUE)))]
    #########
    
    names(sort(colMeans(Entropietemp), decreasing=TRUE))
    multifragen.alt = multifragen
    multifragen.alt
    multifragen = which(names(komus2) %in% names(komusmult[multifragen.alt]))
    modell = NULL
    fitting = NULL
    chances = NULL
    
    if (1 %in% multifragen) {
        modell[[1]] = polr(reformulate('1', names(komus2[1])), data = komus2)
    } else {
        modell[[1]] = glm(reformulate('1', names(komus2[1])), data = komus2, family = "binomial"(link=logit))
    }
    
    for (i in 2:items) {
        if (i %in% multifragen) {
            modell[[i]] = polr(reformulate(names(komus2[1:i-1]), names(komus2[i])), data = komus2)
        } else {
            modell[[i]] = glm(reformulate(names(komus2[1:i-1]), names(komus2[i])), data = komus2, family = "binomial"(link=logit))
        }
    }
    
    fitting = modell
    <<fitting>>
    chances = FUN.Chances(fitting)
    #chances[-multifragen] = mclapply(fitting[-multifragen], predict, type="response")
    #chances[multifragen] = mclapply(fitting[multifragen], predict, type="probs")
    
    #Entropietemp = fitting
    Entropietemp = FUN.Entropietemp(chances)
    #Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC)
    #Entropietemp[-multifragen] =lapply(chances[-multifragen], FUN.Entropie)
    #Entropietemp = simplify2array(Entropietemp)
    
    SumSDtemp = sd(Entropietemp[,1])
    for (i in 2:length(Entropietemp[1,])) {
        SumSDtemp[i] = sd(rowSums(Entropietemp[,1:i]))
    }
    
    SumSD$sortbed = c(0,SumSDtemp)
    
    EEE$sortbed = c(0,colMeans(Entropietemp))
    
    multifragen = multifragen.alt
#+END_SRC

#+RESULTS: statistic2
#+begin_example
 [1] "D34a"     "D41d"     "D32"      "D21d"     "D23b"     "D4235"   
 [7] "D119b13"  "D11613"   "D114a"    "D41f1"    "D113a56"  "D110b12b"
[13] "D113a16"  "D25a"     "D114d"    "D21c22"   "D113a26"  "D114c"   
[19] "D36a"     "D24b"     "D115a23"  "D17"      "D37c"     "D110a35" 
[25] "D41f2"    "D110a25"  "D21c12"   "D26a55"   "D41f3"    "D43a33"  
[31] "D36b"     "D1916"    "D4215"    "D31a"     "D118eMCe" "D24e"    
[37] "D110a15"  "D45a14"   "D12022"   "D12012"   "D119a"    "D37b"    
[43] "D44a44"   "D1926"    "X.D1124"  "D31b"     "D24a"     "D43a23"  
[49] "D45a24"   "D45b26"   "D26b2"    "D115c12"  "D26b1"    "D24h"
[1] 18 24 25 37 38 43
 Warnmeldungen:
1: glm.fit: fitted probabilities numerically 0 or 1 occurred 
2: glm.fit: fitted probabilities numerically 0 or 1 occurred 
3: glm.fit: Angepasste Wahrscheinlichkeiten mit numerischem Wert 0 oder 1 aufgetreten 
4: glm.fit: Angepasste Wahrscheinlichkeiten mit numerischem Wert 0 oder 1 aufgetreten 
5: glm.fit: Algorithmus konvergierte nicht 
6: glm.fit: Angepasste Wahrscheinlichkeiten mit numerischem Wert 0 oder 1 aufgetreten 
7: glm.fit: Angepasste Wahrscheinlichkeiten mit numerischem Wert 0 oder 1 aufgetreten
#+end_example

**** Durchschnittlich bedingtsortierte Entropie
#+NAME: statistic3
#+BEGIN_SRC R :session stat :exports both :results output :noweb yes
    fragen = NULL
    modell = NULL
    Restentropietemp = NULL
    multifragenalt = multifragen
    ############## sortierte Reihenfolge
    for (i in 1:length(komusmult)) {
        if (i %in% multifragen) {
            fitting[[i]] = polr(reformulate('1', names(komusmult[i])), data = komusmult)
        } else {
            fitting[[i]] = glm(reformulate('1', names(komusmult[i])), data = komusmult, family = "binomial"(link=logit))
        }
    }
    #modell
    chances = FUN.Chances(fitting)
    
    Entropietemp = FUN.Entropietemp(chances)
    
    fragen = which(names(komusmult[which(colMeans(Entropietemp) == max(colMeans(Entropietemp)))[1]]) == names(komusmult))[1]
    fragen
    #########
    modell[[1]] = fitting[[fragen]]
    
    for (i in 2:items) {
        Entropietemp = NULL
        fitting = NULL
    
        multifragen = which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt]))
    
        for (j in 1:length(komusmult[-fragen])) {
            if (j %in% multifragen) {
                fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
            } else {
                fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
            }
        }
        <<fitting>>
        chances = FUN.Chances(fitting)
    
        Entropietemp = FUN.Entropietemp(chances)
        Restentropietemp[[i-1]] = rowSums(Entropietemp)
    
        fragen = c(fragen, which(names(komusmult[-fragen][which(colMeans(Entropietemp) == max(colMeans(Entropietemp)))[1]]) == names(komusmult))[1])
        modell[[i]] = fitting[[which(colMeans(Entropietemp) == max(colMeans(Entropietemp)))[1]]]
    }
    
    if (length(komusmult) == items) {
        Restentropietemp[[items]] = Restentropietemp[[1]]*0
    } else {
        fitting = NULL
    
        multifragen = which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt]))
    
        for (j in 1:length(komusmult[-fragen])) {
            if (j %in% multifragen) {
                fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
            } else {
                fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
            }
        }
        <<fitting>>
        chances = FUN.Chances(fitting)
        Entropietemp = FUN.Entropietemp(chances)
        Restentropietemp[[items]] = rowSums(Entropietemp)
    }
    multifragen = which(fragen %in% multifragenalt)
    
    Restentropietemp = simplify2array(Restentropietemp)
    
    chances = FUN.Chances(modell)
    Entropietemp = FUN.Entropietemp(chances)
    
    SumSDtemp = sd(Entropietemp[,1])
    for (i in 2:length(Entropietemp[1,])) {
    SumSDtemp[i] = sd(rowSums(Entropietemp[,1:i]))
    }
    
    SumSD$durchschbedsort = c(0,SumSDtemp)
    EEE$durchschbedsort = c(0,colMeans(Entropietemp))
    RestEntropie$durchschbedsort = c(0,colMeans(Restentropietemp))
    RestEntropieSD$durchschbedsort = c(0,apply(Restentropietemp, 2, sd))
#+END_SRC

#+RESULTS: statistic3
: [1] 38
:  Es gab 50 oder mehr Warnungen (Anzeige der ersten 50 mit warnings())

**** Individuellbedingtsortierte Entropie
#+NAME: statistic4
#+BEGIN_SRC R :session stat :exports both :results output :noweb yes
    ## initializing
    Entropieall = NULL
    chances = NULL
    Restentropietemp = NULL
    fragen = NULL
    modell = NULL
    Restentropietemp = NULL
    multifragen = multifragenalt
    fitting = NULL
    
    ## first item
    for (i in 1:length(komusmult)) {
        if (i %in% multifragen) {
            fitting[[i]] = polr(reformulate('1', names(komusmult[i])), data = komusmult)
        } else {
            fitting[[i]] = glm(reformulate('1', names(komusmult[i])), data = komusmult, family = "binomial"(link=logit))
        }
    }
    
    chances = fitting
    chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[1,], type="response")
    chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[1,], type="probs")
    Entropietemp = FUN.Entropietemp.IND(chances)
    fragen = which(names(komusmult[which(Entropietemp == max(Entropietemp))[1]]) == names(komusmult))[1]
    
    modell[[1]] = fitting[[fragen]]
    frageninit = fragen
    fitting = NULL
    
    ## multicorecalculation for every person
    Entropieall = simplify2array(foreach(k=1:persons) %dopar% {
        fragen = frageninit
        Restentropie = NULL
        for (i in 2:items) {
            chances = NULL
            Entropietemp = NULL
            fitting = NULL
            multifragen = c(0,which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt])))
            for (j in 1:length(komusmult[-fragen])) {
                if (j %in% multifragen) {
                    fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
                } else {
                    fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
                }
            }
             
            <<fitting>>
            chances = fitting
             
            Entropietemp = FUN.EntroMC(multifragen,komusmult[k,], fitting)
           
            Restentropietemp[i-1] = sum(Entropietemp) #rest of entropie before this item
            fragen = c(fragen, which(names(komusmult[-fragen][which(Entropietemp == max(Entropietemp))[1]]) == names(komusmult))[1])
            modell[[i]] = fitting[[which(Entropietemp == max(Entropietemp))[1]]]
        }
        
        ## calculation of last rest entropie
        if (length(komusmult) == items) {
            Restentropietemp[items] = 0
        } else {
            fitting = NULL
            multifragen = 0
            multifragen = c(0,which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt])))
            for (j in 1:length(komusmult[-fragen])) {
                if (j %in% multifragen) {
                    fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
                } else {
                    fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
                }
            }
            <<fitting>>
                
            Entropietemp = FUN.EntroMC(multifragen,komusmult[k,], fitting)
            Restentropietemp[items] = sum(Entropietemp)
        }
        
        ## calculation of the choosen modell
        multifragen = c(0,which(fragen %in% multifragenalt))

        Entropietemp = FUN.EntroMC(multifragen,komusmult[k,], modell)
        return(c(Entropietemp, Restentropietemp))    
    })
    
    Restentropietemp = (Entropieall[(items+1):(items*2),])
    Entropieall = Entropieall[1:items,]
     
    SumSDtemp = sd(Entropieall[1,])
    for (i in 2:length(Entropieall[,1])) {
        SumSDtemp[i] = sd(colSums(Entropieall[1:i,]))
    }
     
    SumSD$indivbedsort = c(0,SumSDtemp)
    EEE$indivbedsort = c(0,rowMeans(Entropieall))
    RestEntropie$indivbedsort = c(0,rowMeans(Restentropietemp))
    RestEntropieSD$indivbedsort = c(0,apply(Restentropietemp, 1, sd))
    
    multifragen = multifragenalt
#+END_SRC

#+RESULTS: statistic4

**** Individuellbedingtsortierte Entropie mit Trennschärfe
#+NAME: statistic5
#+BEGIN_SRC R :session stat :exports both :results output :noweb yes
    Entropieall = NULL
    chances = NULL
    beta = NULL
    Restentropietemp = NULL
    Entropietemp = NULL
    fitting = NULL
    
    if (!exists("information")) {
        information = simplify2array(foreach(m=1:length(komus)) %dopar% {
            for (n in 1:(length(komus)-1)) {
                beta[[n]] = glm(reformulate(names(komus[m]), names(komus[-m][n])), data = komus, family = "binomial"(link=logit))
            }
            chances = simplify2array(lapply(beta, predict, type="response"))
            chancetemp = unlist(lapply(komus[m],mean))
            Entropietemp = (-chances*log(chances,2)-(1-chances)*log(1-chances,2))
            information = sum(colMeans(Entropietemp)) + (-chancetemp*log(chancetemp,2)-(1-chancetemp)*log(1-chancetemp,2))
            return(information)
        })
        information = -(information - sum(-colMeans(komus)*log(colMeans(komus),2)-(1-colMeans(komus))*log(1-colMeans(komus),2)))
    }
    
    
    
    
    
    for (j in 1:length(komus)) {
        fitting[[j]] = glm(reformulate('1', names(komus[j])), data = komus, family = "binomial"(link=logit))
    }
    <<fitting>>
    chances = simplify2array(lapply(fitting, predict, komus[1,], type="response"))
    Entropietemp = (-chances*log(chances,2)-(1-chances)*log(1-chances,2)) + (information)
    frageninit = which(names(komus[which((Entropietemp) == max((Entropietemp)))[1]]) == names(komus))[1]
    
     
    
    modell[[1]] = fitting[[which((Entropietemp) == max((Entropietemp)))[1]]]
    
    Entropieall = simplify2array(foreach(k=1:persons) %dopar% {
        fragen = frageninit
        for (i in 2:items) {
            Entropietemp = NULL
            fitting = NULL
            for (j in 1:length(komus[-fragen])) {
                fitting[[j]] = glm(reformulate(names(komus[fragen]), names(komus[-fragen][j])), data = komus, family = "binomial"(link=logit))
            }
    
            <<fitting>>
            ## TODO stimmt das so?
            chances = simplify2array(lapply(fitting, predict, komus[k,], type="response"))
            Restentropietemp[i-1] = sum(-chances*log(chances,2)-(1-chances)*log(1-chances,2)) 
            Entropietemp = (-chances*log(chances,2)-(1-chances)*log(1-chances,2)) + (information[-fragen]*(1 - (length(fragen)+1)/items))
            fragen = c(fragen, which(names(komus[-fragen][which((Entropietemp) == max((Entropietemp)))[1]]) == names(komus))[1])
            modell[[i]] = fitting[[which((Entropietemp) == max((Entropietemp)))[1]]]
        }
    
        if (length(komus) == items) {
            Restentropietemp[items] = 0
        } else {
            fitting = NULL
            for (j in 1:length(komus[-fragen])) {
                fitting[[j]] = glm(reformulate(names(komus[fragen]), names(komus[-fragen][j])), data = komus, family = "binomial"(link=logit))
            }
            <<fitting>>
            chances = simplify2array(lapply(fitting, predict, komus[k,], type="response"))
            Restentropietemp[length(fragen)] = sum(-chances*log(chances,2)-(1-chances)*log(1-chances,2))
        }
    
        chances = simplify2array(lapply(modell, predict, komus[k,], type="response"))
        Entropietemp = (-chances*log(chances,2)-(1-chances)*log(1-chances,2))
        
        return(c(Entropietemp, Restentropietemp))
    })
    
    Restentropietemp = (Entropieall[(items+1):(items*2),])
    Entropieall = Entropieall[1:items,]
    SumSDtemp = sd(Entropieall[1,])
    for (i in 2:length(Entropieall[,1])) {
    SumSDtemp[i] = sd(colSums(Entropieall[1:i,]))
    }
    
    SumSD$indivbedsorttrenn = c(0,SumSDtemp )
    EEE$indivbedsorttrenn = c(0,rowMeans(Entropieall))
    RestEntropie$indivbedsorttrenn = c(0,rowMeans(Restentropietemp))
    RestEntropieSD$indivbedsorttrenn = c(0,apply(Restentropietemp,1 ,sd))
#+END_SRC

#+RESULTS: statistic5

**** Individuellbedingtsortierte Entropie mit Prädiktion
#+NAME: statistic6
#+BEGIN_SRC R :session stat :exports code :results output :noweb yes
    ## initializing
    fitting = NULL
    Entropieall = NULL
    chances = NULL
    Restentropietemp = NULL
    fragen = NULL
    modell = NULL
    Restentropietemp = NULL
    multifragen = multifragenalt
    
    ## first item
    for (i in 1:length(komusmult)) {
        if (i %in% multifragen) {
            fitting[[i]] = polr(reformulate('1', names(komusmult[i])), data = komusmult)
        } else {
            fitting[[i]] = glm(reformulate('1', names(komusmult[i])), data = komusmult, family = "binomial"(link=logit))
        }
    }
    
    chances = fitting
    chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[1,], type="response")
    chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[1,], type="probs")
    Entropietemp = FUN.Entropietemp.IND(chances)
    fragen = which(names(komusmult[which(Entropietemp == max(Entropietemp))[1]]) == names(komusmult))[1]
    
    modell[[1]] = fitting[[fragen]]
    frageninit = fragen
    fitting = NULL
    Restentropie2 = NULL
    
    ## multicore calculation
    Entropieall = simplify2array(foreach(k=1:persons) %dopar% {
        fragen = frageninit
        Restentropie = NULL
        Restentropietemp2 = NULL
        Restentropietemp = NULL
        for (i in 2:items) {
            chances = NULL
            Entropietemp = NULL
            fitting = NULL
            fitting2 = NULL
            fittingplus = NULL
            fittingminus = NULL
            Entropietemp2 = NULL
            multifragen = 0
            multifragen = c(multifragen,which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt])))
            
            ## prediction for all not-answerd questions
            for (j in 1:length(komusmult[-fragen])) {
                if (j %in% multifragen) {
                    fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
                } else {
                    fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
                }
                
                ## prediction for all not-answered questions after prediction
                if (length(komusmult[-fragen]) > 1) {
                    multifragen2 = c(0,which(names(komusmult[-fragen][-j]) %in% names(komusmult[multifragenalt])))
                    for (n in 1:length(komusmult[-fragen][-j])) {
                        if (n %in% multifragen2) {
                            fitting2[[n]] = polr(reformulate(names(c(komusmult[fragen], komusmult[-fragen][j])), names(komusmult[-fragen][-j][n])), data = komusmult)
                        } else {
                            fitting2[[n]] = glm(reformulate(names(c(komusmult[fragen], komusmult[-fragen][j])), names(komusmult[-fragen][-j][n])), data = komusmult, family = "binomial"(link=logit))
                        }
                    }
                    
                    ## calculation of rest entropie for each possibility
                    tempdata = komusmult[k,]
                    ##tempdata[-fragen][j] = 0 #dies muss noch bearbeitet werden (chancen...)
                    <<fitting>>
#                        chances = fitting2
#                    if (length(multifragen2) == 1) {
#                        chances = lapply(fitting2, predict, tempdata, type="response")
#                        Entropietemp = chances
#                        Entropietemp = lapply(chances, FUN.Entropie)
#                        Entropietemp = simplify2array(Entropietemp)
#                    } else {
#                        multifragen2 = multifragen2[2:length(multifragen2)]
#                        chances[-multifragen2] = lapply(fitting2[-multifragen2], predict, tempdata, type="response")
#                        chances[multifragen2] = lapply(fitting2[multifragen2], predict, tempdata, type="probs")
#                        Entropietemp = chances
#                        
#                        ## Funktion kann nicht benutzt werden, da sie auf nicht manipulierte multifragen zugreift
#                        Entropietemp[multifragen2] = lapply(chances[multifragen2], FUN.EntropieMC.IND)
#                        Entropietemp[-multifragen2] = lapply(chances[-multifragen2], FUN.Entropie)
#                        Entropietemp = simplify2array(Entropietemp)
#                    }
                    Entropietemp = FUN.EntroMC(multifragen2,tempdata, fitting2)
                    Restentropietemp2[j] = sum(Entropietemp)
                } else {
                    Restentropietemp2[j] = 0 
                }
            }
            
            <<fitting>>
                chances = fitting
            
#            ## calculation of current rest entropie
#            if (length(multifragen) == 1) {
#                chances = lapply(fitting, predict, komusmult[k,], type="response")
#                Entropietemp = chances
#                Entropietemp = lapply(chances, FUN.Entropie)
#                Entropietemp = simplify2array(Entropietemp)
#            } else {
#                multifragen = multifragen[2:length(multifragen)]
#                chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[k,], type="response")
#                chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[k,], type="probs")
#                Entropietemp = chances
#                
#                ## Funktion kann nicht benutzt werden, da sie auf nicht manipulierte multifragen zugreift
#                Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC.IND)
#                Entropietemp[-multifragen] = lapply(chances[-multifragen], FUN.Entropie)
#                Entropietemp = simplify2array(Entropietemp)
#            }
            Entropietemp = FUN.EntroMC(multifragen,komusmult[k,], fitting)
            Restentropietemp[i-1] = sum(Entropietemp)
            fragen = c(fragen, which(names(komusmult[-fragen][which(Restentropietemp2 == min(Restentropietemp2))[1]]) == names(komusmult))[1])
            ## stimmt das? sollte das nicht mit Restentropietemp2 arbeiten?
            ##        modell[[i]] = fitting[[which(Entropietemp == max(Entropietemp))]]
            modell[[i]] = fitting[[which(Restentropietemp2 == min(Restentropietemp2))[1]]]
        }
        
        ## calculation of last rest entropie
        if (length(komusmult) == items) {
            Restentropietemp[items] = 0
        } else {
            fitting = NULL
            multifragen = 0
            multifragen = c(0,which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt])))
            for (j in 1:length(komusmult[-fragen])) {
                if (j %in% multifragen) {
                    fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
                } else {
                    fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
                }
            }
            
            <<fitting>>
#                if (length(multifragen) == 1) {
#                    chances = lapply(fitting, predict, komusmult[k,], type="response")
#                    Entropietemp = chances
#                    Entropietemp = lapply(chances, FUN.Entropie)
#                    Entropietemp = simplify2array(Entropietemp) 
#                } else {
#                    multifragen = multifragen[2:length(multifragen)]
#                    chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[k,], type="response")
#                    chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[k,], type="probs")
#                    Entropietemp = chances
#                    
#                    ## Funktion kann nicht benutzt werden, da sie auf nicht manipulierte multifragen zugreift
#                    Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC.IND)
#                    Entropietemp[-multifragen] = lapply(chances[-multifragen], FUN.Entropie)
#                    Entropietemp = simplify2array(Entropietemp)
#                }
            Entropietemp = FUN.EntroMC(multifragen,komusmult[k,], fitting)
        Restentropietemp[items] = sum(Entropietemp)
        }
        
        ## calculation of choosen modell
        multifragen = 0
        multifragen = c(multifragen,which(fragen %in% multifragenalt))
#        if (length(multifragen) == 1) {
#            chances = modell
#            chances = lapply(modell, predict, komusmult[k,], type="response")
#            Entropietemp = chances
#            Entropietemp = lapply(chances, FUN.Entropie)
#            Entropietemp = simplify2array(Entropietemp)
#        } else {
#            multifragen = multifragen[2:length(multifragen)]
#            chances = modell
#            chances[-multifragen] = lapply(modell[-multifragen], predict, komusmult[k,], type="response")
#            chances[multifragen] = lapply(modell[multifragen], predict, komusmult[k,], type="probs")
#            Entropietemp = chances
#            
#            ## Funktion kann nicht benutzt werden, da sie auf nicht manipulierte multifragen zugreift
#            Entropietemp[multifragen] = lapply(chances[multifragen], FUN.EntropieMC.IND)
#            Entropietemp[-multifragen] = lapply(chances[-multifragen], FUN.Entropie)
#            Entropietemp = simplify2array(Entropietemp)
#        }
        Entropietemp = FUN.EntroMC(multifragen,komusmult[k,], modell)
        return(c(Entropietemp, Restentropietemp))    
    })
    
    Restentropietemp = (Entropieall[(items+1):(items*2),])
    Entropieall = Entropieall[1:items,]
    
    SumSDtemp = sd(Entropieall[1,])
    for (i in 2:length(Entropieall[,1])) {
        SumSDtemp[i] = sd(colSums(Entropieall[1:i,]))
    }
    
    SumSD$indivbedsortpred = c(0,SumSDtemp)
    EEE$indivbedsortpred = c(0,rowMeans(Entropieall))
    RestEntropie$indivbedsortpred = c(0,rowMeans(Restentropietemp))
    RestEntropieSD$indivbedsortpred = c(0,apply(Restentropietemp, 1, sd))
    
    multifragen = multifragenalt
    EEE
    SumSD
    RestEntropie
    RestEntropieSD
#+END_SRC

**** Experimenteller Code
#+BEGIN_SRC R :session stat :exports code :results output :noweb yes
        calculationtime <- proc.time()
        
            ## initializing
            fitting = NULL
            Entropieall = NULL
            chances = NULL
            Restentropietemp = NULL
            fragen = NULL
            modell = NULL
            Restentropietemp = NULL
            multifragen = multifragenalt
            
            ## first item
            for (i in 1:length(komusmult)) {
                if (i %in% multifragen) {
                    fitting[[i]] = polr(reformulate('1', names(komusmult[i])), data = komusmult)
                } else {
                    fitting[[i]] = glm(reformulate('1', names(komusmult[i])), data = komusmult, family = "binomial"(link=logit))
                }
            }
            
            chances = fitting
            chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[1,], type="response")
            chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[1,], type="probs")
            Entropietemp = FUN.Entropietemp.IND(chances)
            fragen = which(names(komusmult[which(Entropietemp == max(Entropietemp))[1]]) == names(komusmult))[1]
            
            modell[[1]] = fitting[[fragen]]
            frageninit = fragen
            fitting = NULL
            Restentropie2 = NULL
            ## multicore calculation
        #    Entropieall = simplify2array(foreach(k=1:persons) %dopar% {
            for (k in 1:persons) {
                fragen = frageninit
                Restentropie = NULL
                Restentropietemp2 = NULL
                Restentropietemp = NULL
                antwortmuster = vector(length=(length(komusmult)*2))
                schongerechnet = read.table('database.dat')
                antwortmuster[1] = fragen[1]
                antwortmuster[2] = komusmult[k,fragen[1]]
                for (i in 2:items) {
                    chances = NULL
                    Entropietemp = NULL
                    fitting = NULL
                    fitting2 = NULL
                    fittingplus = NULL
                    fittingminus = NULL
                    Entropietemp2 = NULL
                    found = 0
                    multifragen = c(0,which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt])))
                    Liste = NULL
        
                    ## prediction for all not-answerd questions
                    for (m in 1:length(schongerechnet[,1])) {
                        for (z in 1:length(fragen)*2) {
                            if (antwortmuster[z] != schongerechnet[m,z]) {
                                found = 0
                                break
                            } else { if (length(schongerechnet[m,]) > z && schongerechnet[m,(z+1)] != 0 && z == length(fragen)*2) {
                                found = schongerechnet[m,(z+1)]}
                            }
                        }
                        if (found != 0) {
                            break
                        }
                    }
                        Liste =foreach(j=1:length(komusmult[-fragen])) %dopar% {
                            if (j %in% multifragen) {
                                fitting = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
                            } else {
                                fitting = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
                            }
                            if (found == 0) {
                                ## prediction for all not-answered questions after prediction
                                if (length(komusmult[-fragen]) > 1) {
                                    multifragen2 = c(0,which(names(komusmult[-fragen][-j]) %in% names(komusmult[multifragenalt])))
                                    for (n in 1:length(komusmult[-fragen][-j])) {
                                        if (n %in% multifragen2) {
                                            fitting2[[n]] = polr(reformulate(names(c(komusmult[fragen], komusmult[-fragen][j])), names(komusmult[-fragen][-j][n])), data = komusmult)
                                        } else {
                                            fitting2[[n]] = glm(reformulate(names(c(komusmult[fragen], komusmult[-fragen][j])), names(komusmult[-fragen][-j][n])), data = komusmult, family = "binomial"(link=logit))
                                        }
                                    }
                                    
                                    ## calculation of rest entropie for each possibility
                                    tempdata = komusmult[k,]
                                    ##tempdata[-fragen][j] = 0 #dies muss noch bearbeitet werden (chancen...)
                                    <<fitting>>
                                        
                                        Entropietemp = FUN.EntroMC(multifragen2,tempdata, fitting2)
                                    Restentropietemp2 = sum(Entropietemp)
                                } else {
                                    Restentropietemp2 = 0 
                                }
                                return(c(list(fitting), list(Restentropietemp2)))
                            } else {
                                return(fitting)
                            }
                        }
                        if (found == 0) {
                            Liste = unlist(Liste, recursive = FALSE)
                            
                            Restentropietemp2 = unlist(Liste[(1:(length(Liste)/2))*2])
                            fitting = Liste[(1:(length(Liste)/2))*2-1]
                                            #            fitting = Liste[1:length(komusmult[-fragen])]
                                            #            Restentropietemp2 =unlist(Liste[(length(komusmult[-fragen])+1):length(Liste)])
                            fragen = c(fragen, which(names(komusmult[-fragen][which(Restentropietemp2 == min(Restentropietemp2))[1]]) == names(komusmult))[1])
                            modell[[i]] = fitting[[which(Restentropietemp2 == min(Restentropietemp2))[1]]]
                        } else {
                            fitting = Liste
                            modell[[i]] = fitting[[which(names(komusmult[found]) == names(komusmult[-fragen])) ]]
                            fragen = c(fragen, found)
    
                        }
                    <<fitting>>
                        chances = fitting
                    
                        Entropietemp = FUN.EntroMC(multifragen,komusmult[k,], fitting)
                        Restentropietemp[i-1] = sum(Entropietemp)
    
                        write(antwortmuster, file='database.dat', append=TRUE, ncolumns=length(antwortmuster))
          
                    antwortmuster[i*2-1] = fragen[i]
                    antwortmuster[i*2] = komusmult[k,fragen[i]]
        
        
                    plot(Restentropietemp, type='l', col=rgb(0,0.7,0.7))
                }
                ## calculation of last rest entropie
                if (length(komusmult) == items) {
                    Restentropietemp[items] = 0
                } else {
                    fitting = NULL
                    multifragen = 0
                    multifragen = c(0,which(names(komusmult[-fragen]) %in% names(komusmult[multifragenalt])))
                    for (j in 1:length(komusmult[-fragen])) {
                        if (j %in% multifragen) {
                            fitting[[j]] = polr(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult)
                        } else {
                            fitting[[j]] = glm(reformulate(names(komusmult[fragen]), names(komusmult[-fragen][j])), data = komusmult, family = "binomial"(link=logit))
                        }
                    }
                    
                    <<fitting>>
        
                    Entropietemp = FUN.EntroMC(multifragen,komusmult[k,], fitting)
                Restentropietemp[items] = sum(Entropietemp)
                }
                
                ## calculation of choosen modell
                multifragen = 0
                multifragen = c(multifragen,which(fragen %in% multifragenalt))
        
                Entropietemp = FUN.EntroMC(multifragen,komusmult[k,], modell)
            #    return(c(Entropietemp, Restentropietemp))    
            }#})
            
            #Restentropietemp = (Entropieall[(items+1):(items*2),])
            #Entropieall = Entropieall[1:items,]
            
            SumSDtemp = sd(Entropieall[1,])
            for (i in 2:length(Entropieall[,1])) {
                SumSDtemp[i] = sd(colSums(Entropieall[1:i,]))
            }
            
            SumSD$indivbedsortpred = c(0,SumSDtemp)
            EEE$indivbedsortpred = c(0,rowMeans(Entropieall))
            RestEntropie$indivbedsortpred = c(0,rowMeans(Restentropietemp))
            RestEntropieSD$indivbedsortpred = c(0,apply(Restentropietemp, 1, sd))
            
            multifragen = multifragenalt
            EEE
            SumSD
            RestEntropie
            RestEntropieSD
#+END_SRC

#+RESULTS:
#+begin_example
 Fehler in fitting[[which(names(komusmult[found]) == names(komusmult[-fragen]))]] (von #81) : 
  Versuch weniger als ein Element zu wählen
Fehler in var(as.vector(x), na.rm = na.rm) : 'x' ist NULL
 Fehler in colSums(Entropieall[1:i, ]) (von #2) : 
  'x' must be an array of at least two dimensions
Fehler: Objekt 'SumSDtemp' nicht gefunden
Fehler in rowMeans(Entropieall) : 
  'x' muss ein Array mit mindestens zwei Dimensionen sein
Fehler in rowMeans(Restentropietemp) : 
  'x' muss ein Array mit mindestens zwei Dimensionen sein
Fehler in apply(Restentropietemp, 1, sd) : 
  dim(X) muss positive Länge haben
   kill
1    NA
2    NA
3    NA
4    NA
5    NA
6    NA
7    NA
8    NA
9    NA
10   NA
11   NA
12   NA
13   NA
14   NA
15   NA
16   NA
17   NA
18   NA
19   NA
20   NA
21   NA
22   NA
23   NA
24   NA
25   NA
26   NA
27   NA
28   NA
29   NA
30   NA
31   NA
32   NA
33   NA
34   NA
35   NA
36   NA
37   NA
38   NA
39   NA
40   NA
41   NA
42   NA
43   NA
44   NA
45   NA
46   NA
47   NA
48   NA
49   NA
50   NA
51   NA
52   NA
53   NA
54   NA
55   NA
   kill
1    NA
2    NA
3    NA
4    NA
5    NA
6    NA
7    NA
8    NA
9    NA
10   NA
11   NA
12   NA
13   NA
14   NA
15   NA
16   NA
17   NA
18   NA
19   NA
20   NA
21   NA
22   NA
23   NA
24   NA
25   NA
26   NA
27   NA
28   NA
29   NA
30   NA
31   NA
32   NA
33   NA
34   NA
35   NA
36   NA
37   NA
38   NA
39   NA
40   NA
41   NA
42   NA
43   NA
44   NA
45   NA
46   NA
47   NA
48   NA
49   NA
50   NA
51   NA
52   NA
53   NA
54   NA
55   NA
   kill
1    NA
2    NA
3    NA
4    NA
5    NA
6    NA
7    NA
8    NA
9    NA
10   NA
11   NA
12   NA
13   NA
14   NA
15   NA
16   NA
17   NA
18   NA
19   NA
20   NA
21   NA
22   NA
23   NA
24   NA
25   NA
26   NA
27   NA
28   NA
29   NA
30   NA
31   NA
32   NA
33   NA
34   NA
35   NA
36   NA
37   NA
38   NA
39   NA
40   NA
41   NA
42   NA
43   NA
44   NA
45   NA
46   NA
47   NA
48   NA
49   NA
50   NA
51   NA
52   NA
53   NA
54   NA
55   NA
   kill
1    NA
2    NA
3    NA
4    NA
5    NA
6    NA
7    NA
8    NA
9    NA
10   NA
11   NA
12   NA
13   NA
14   NA
15   NA
16   NA
17   NA
18   NA
19   NA
20   NA
21   NA
22   NA
23   NA
24   NA
25   NA
26   NA
27   NA
28   NA
29   NA
30   NA
31   NA
32   NA
33   NA
34   NA
35   NA
36   NA
37   NA
38   NA
39   NA
40   NA
41   NA
42   NA
43   NA
44   NA
45   NA
46   NA
47   NA
48   NA
49   NA
50   NA
51   NA
52   NA
53   NA
54   NA
55   NA
#+end_example


**** Exp2
#+BEGIN_SRC R :session stat :results output

mupp = vector(length = length(komusmult)*2)
mup = c(fragen, 0:(length(komusmult)-length(fragen))*0)

#+END_SRC

**** Schlussberechnungen
#+NAME: statisticend
#+BEGIN_SRC R :session stat :exports both :results output :noweb yes
    if (names(EEE[1]) == 'kill') {
        EEE = EEE[-1]
    }
    
    if (names(SumSD[1]) == 'kill') {
        SumSD = SumSD[-1]
    }
    
    if (names(RestEntropie[1]) == 'kill') {
        RestEntropie = RestEntropie[-1]
        RestEntropieSD = RestEntropieSD[-1]
    }
    
    for (i in 1:length(EEE[1,])) {
        for (j in 1:length(EEE[,1])) {
            summe[j,i] = sum(EEE[1:j,i])
        }
    }
    
    fitting = NULL
    multifragen = multifragenalt
    for (i in 1:length(komusmult)) {
        if (i %in% multifragen) {
            fitting[[i]] = polr(reformulate('1', names(komusmult[i])), data = komusmult)
        } else {
            fitting[[i]] = glm(reformulate('1', names(komusmult[i])), data = komusmult, family = "binomial"(link=logit))
        }
    }
    
    chances = fitting
    chances[-multifragen] = lapply(fitting[-multifragen], predict, komusmult[1,], type="response")
    chances[multifragen] = lapply(fitting[multifragen], predict, komusmult[1,], type="probs")
    Entropietemp = FUN.Entropietemp.IND(chances)
    RestEntropie[1,] = sum(Entropietemp)
    
    names(summe) = names(EEE)
    
    if (exists("benchmark")) {
        benchmark = array(c(benchmark,(proc.time() - calculationtime)[3]))
    } else {
        benchmark = (proc.time() - calculationtime)[3]
    }
    EEE
    benchmark
#+END_SRC

#+RESULTS: statisticend
#+begin_example
    indivbedsort
1   0.000000e+00
2   2.721777e+00
3   2.427458e+00
4   2.126014e+00
5   1.992156e+00
6   1.575451e+00
7   9.999204e-01
8   9.998602e-01
9   9.989127e-01
10  9.991282e-01
11  9.995284e-01
12  9.999209e-01
13  9.972336e-01
14  9.984596e-01
15  9.969846e-01
16  9.931958e-01
17  9.923221e-01
18  9.995902e-01
19  9.992221e-01
20  9.993786e-01
21  9.875261e-01
22  9.788383e-01
23  9.863772e-01
24  9.813786e-01
25  9.838993e-01
26  9.762137e-01
27  9.867093e-01
28  9.616413e-01
29  9.840549e-01
30  9.854389e-01
31  9.882042e-01
32  9.831196e-01
33  9.113060e-01
34  9.166238e-01
35  9.292785e-01
36  8.245181e-01
37  7.587426e-01
38  7.680600e-01
39  6.930407e-01
40  6.497156e-01
41  6.146780e-01
42  6.153897e-01
43  4.743017e-01
44  4.623109e-01
45  3.508635e-01
46  4.273289e-01
47  3.170230e-01
48  3.310405e-01
49  2.412251e-01
50  1.647116e-01
51  1.622951e-01
52  5.534671e-02
53  9.756421e-03
54  4.359435e-03
55 -7.934786e-06
[1] 129.069 116.294 137.056 278.572 294.585 227.430 234.996 540.810
#+end_example

**** Formel für die Modellanpassung
#+NAME: fitting
#+BEGIN_SRC R
#fitting = mclapply(fitting, step, trace = 0)
#fitting = mclapply(fitting, step, ~.^2, trace = 0)
#+END_SRC

**** Benchmark
#+BEGIN_SRC R :session stat :noweb yes :results output graphics :file /images/benchmark.png :exports both
plot(benchmark, type="l", col=rgb(0,0,0), ann=F)
title(xlab="Durchlauf")
title(ylab="Dauer")
#+END_SRC

#+RESULTS:
[[file:/images/benchmark.png]]

**** Entropiegrafik
#+NAME: grafik
#+BEGIN_SRC R :session stat :noweb yes :results output graphics :file /images/entropie2.png :exports both
    
    farbe = NULL
    farbeSD = NULL
    for (j in 1:(length(summe[1,]))) {
        r = runif(1,0.1,0.9)
        g = runif(1,0.1,0.9)
        b = runif(1,0.1,0.9)
        farbe[j] = rgb(r^1.2, g^1.2, b^1.2)
        farbeSD[j] = rgb(sqrt(r), sqrt(g), sqrt(b))
    }
    
    plot(0:(length(komusmult)), type="l", col=rgb(0,0,0), ann=F)
    for (i in 1:(length(summe[1,]))) {
        lines(summe[,i], col=farbe[i])
        if (dim(SumSD[names(SumSD) == names(summe[i])])[2] != 0) {
            lines(summe[,i]+SumSD[names(summe[i])],lty = 4, col=farbeSD[i])
            lines(summe[,i]-SumSD[names(summe[i])],lty = 4, col=farbeSD[i])
        }
        if (dim(RestEntropie[names(RestEntropie) == names(summe[i])])[2] != 0) {
            lines(RestEntropie[names(summe[i])], col=farbe[i])
            lines(RestEntropie[names(summe[i])]+RestEntropieSD[names(summe[i])],lty = 4, col=farbeSD[i])
            lines(RestEntropie[names(summe[i])]-RestEntropieSD[names(summe[i])],lty = 4, col=farbeSD[i])
        }
    }
    
    title(xlab="Anzahl der beantworteten Fragen")
    title(ylab="Entropie in bit")
    legend(length(komusmult)/4, length(komusmult), c(names(summe), round(benchmark[length(benchmark)])), cex=0.9, col=c(farbe, rgb(1,1,1)), lty=1);
#+END_SRC

#+RESULTS: grafik
[[file:/images/entropie2.png]]
